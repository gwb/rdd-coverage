{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* People: \n",
    "    * Luke Bornn: Assistant Professor of Statistics at Simon Fraser University and a Visiting Scholar at Harvard University\n",
    "    * Luke Miratrix: Assistant Professor at GSE, was assistant professor in our department until last year\n",
    "    * Zach: you know Zach\n",
    "* My talk in one slide:\n",
    "    * take Zach's talk\n",
    "        * the treatment assignment is dictated by a single covariate\n",
    "        * that divides the data into two groups\n",
    "        * we then fit a GP to each group\n",
    "        * extrapolate to the boundary from both sides\n",
    "        * take the difference of the two extrapolations to get our estimate of the treatment effect\n",
    "    * we look at the spatial version of this setting\n",
    "    * where geography is dictating the treatment assignment\n",
    "    * data is now distributed geographically\n",
    "    * treatment gets applied to a certain region\n",
    "    * the boundary is a line rather than a point\n",
    "    * again, we can fit a GP on either side, extrapolate to the boundary, and subtract\n",
    "    * but instead of getting a scalar, that gives us a one-dimensional GP, which I call the cliff face\n",
    "* Quick example of what we've seen in the literature\n",
    "    * map of the Penn campus in Philadelphia\n",
    "    * the Penn campus is patrolled by a private university police force\n",
    "    * the researchers want to know whether the presence of that force reduces crime\n",
    "    * the units are the city blocks, the outcome is the number of crimes in that block\n",
    "    * it's a 2-dimensional problem, but they treat it as 1-dimensional, by looking at crime vs. distance from the boundary\n",
    "    * once they've done that, they can use classical RDD methodologies\n",
    "    * the other approach to this we've seen in the literature is matching units across the boundary\n",
    "    * we think we can do better by treating it as a spatial problem explicitly\n",
    "* Setup\n",
    "    * setup: a treatment gets applied to a certain region\n",
    "    * and this region neighbors another region where the treatment isn't applied: a control population\n",
    "    * can think of two potential outcome surfaces on the entire space\n",
    "        * but only $Y_T$ gets observed in the treatment region\n",
    "        * and only $Y_C$ in the control region\n",
    "* We explored two possible models\n",
    "    * the first is what we call the **1GP solution**\n",
    "    * we model the potential outcomes as a **single Gaussian process**\n",
    "    * but with a **constant treatment effect** added to the units in the treatment region\n",
    "    * very **simple** model to understand, but it suffers from a few **flaws**\n",
    "    * first, the **constant treatment effect** assumption is really strong\n",
    "    * second, the Gaussian process is smooth, and so the **gradient** must be the same on both sides of the discontinuity\n",
    "    * and thirdly, we discovered that this model **doesn't just use information near the boundary**\n",
    "    * after all, the average in the control group is $\\mu$, but $\\mu + \\tau$, so given enough data however far away from the boundary, the inference $\\tau$ will converge towards the difference in means\n",
    "    * the fact that data far away from the boundary can be so informative about the treatment effect is a **violation of the philosophy of regression discontinuity designs**\n",
    "* This led us to the 2GP solution\n",
    "    * where we **fit a Gaussian Process on both sides** of the boundary\n",
    "    * which is the 2-dimensional **analog of the methodology Zach presented**\n",
    "    * the treatment effect is no longer an **explicit part of the model**\n",
    "    * instead it is the difference between the two surfaces\n",
    "    * theoretically, the treatment effect is defined everywhere, but just like in the 1D setting, we're not in a position to estimate it everywhere\n",
    "    * so we focus on the boundary\n",
    "* Just to make the procedure explicit\n",
    "    * we take the data in the treatment and control regions\n",
    "    * and **separately** fit GPs to them\n",
    "    * we **extrapolate** both GPs to the boundary, obtaining predictive means and covariance\n",
    "    * we then take the **difference** of the two extrapolations to obtain an estimate of the treatment effect along the boundary: what I call the **“cliff-face estimate”**\n",
    "    * interestingly, this treatment effect cliff-face **is itself a one-dimensional Gaussian process**\n",
    "    * computationally, we estimate it at a set of points along the boundary, which we call **sentinel units**\n",
    "* Example: **house prices** in NYC\n",
    "    * downloaded a year's worth of sales data in NYC\n",
    "    * NYC is divided into several school districts\n",
    "    * children who live within a school district are guaranteed attendance in a school within their district, otherwise they have to apply\n",
    "    * some of these districts perform much better than others\n",
    "    * **question**: to the school districts drive house prices?\n",
    "    * in particular, moving across school district lines, do we observe a discontinuous jump in house prices?\n",
    "    * *stare at heat map*\n",
    "    * we'll focus on districts 19 and 27, which look like they might have a discontinuity\n",
    "    * incidentally, that's also the boundary between Brooklyn and Queens (boroughs of New York), so the causal story is murky\n",
    "    * but our focus is on detecting and quantifying discontinuities, we'll leave these interesting issues aside\n",
    "* Histogram\n",
    "    * does suggest a difference\n",
    "* Procedure\n",
    "    * here we also have **covariates**: the building classes (single family home, condo, apartment building, ...)\n",
    "    * we want to integrate them into our analysis\n",
    "    * this is very hard to do in classical regression discontinuity designs\n",
    "    * but with Gaussian processes it's easy\n",
    "    * we just add a $D \\gamma$ term to the model, where $D$ is a model matrix of additional covariates, and $\\gamma$ is a vector of regression coefficients\n",
    "    * by putting a normal prior on $\\gamma$, the linear regression terms adds a component $\\sigma_\\gamma^2 D^\\intercal D$ to the model matrix ($\\rightarrow$ ridge regression)\n",
    "    * but it's still a GP! so all the MVN machinery still works\n",
    "    * what we do next is obtain the maximum likelihood estimator for all the **hyperparameters**: $\\sigma_y$, $\\sigma_{GP}$ and $\\sigma_\\gamma$\n",
    "    * to simplify the problem, we extract the posterior mean on the $\\gamma$ coefficients, using **only district 27 data** to avoid any possibility of the treatment affecting the estimates, and then subtract the linear regression term to get residuals\n",
    "    * we then **fit** a Gaussian process **to the residuals** on either side\n",
    "    * **extrapolate** to the boundary\n",
    "    * **subtract** the predictions\n",
    "    * and then **make some plots**\n",
    "* So now we've got our cliff face: so what?\n",
    "    * we want to ask questions about the treatment effect\n",
    "    * first, what is the **average** treatment effect?\n",
    "    * but what does it mean to average over the boundary?\n",
    "    * amongst ourselves we had quite a debate over the best way to do this averaging\n",
    "    * the most obvious way is to just take the simple mean of the estimated treatment effect at each sentinel location\n",
    "* But there are issues with this simple averaging\n",
    "    * I'll illustrate the first issue with the border between Louisiana and Mississippi\n",
    "    * the border first follows the Mississippi river, then becomes a straight horizontal lign, then follows the Pearl river\n",
    "    * let's see what happens when we add sentinels\n",
    "    * more sentinels get added to the meanderous section of the border than the straight section\n",
    "    * so when we do the simple average, we give more weight to wiggly sections\n",
    "    * this is **troubling**: it means our estimand and estimator depend heavily on the wiggliness of the rivers, even though our treatment effect **probably has nothing to do with rivers**\n",
    "* Second issue\n",
    "    * this is the border between McHenry and Lake counties in Illinois\n",
    "    * the border goes through a lake and then near the city of McHenry\n",
    "    * the variance of the cliff-face will be very high in the lake, and much lower near the populated region\n",
    "    * but the unweighted mean treats both equally\n",
    "    * this problem can be resolved by taking a **density-weighted mean**, using some kind of density estimates\n",
    "    * we've implemented some version of this, but it doesn't solve the first problem (wiggliness-sensitivity)\n",
    "* My solution: **inverse-variance weighted mean**\n",
    "    * in my view, the most natural way to summarize the information contained in the treatment effect cliff face\n",
    "    * gives more weight to sections of the boundary that we have better estimates for\n",
    "    * does so in a way that accounts for the correlation structure of the cliff-face\n",
    "    * inverse-variance weights are also guaranteed to minimize the variance of a weighted mean: nice bonus\n",
    "    * it's in the spirit of the regression-discontinuity design: we estimate the treatment effect only where we actually have information about it\n",
    "    * but there's a problem: we don't know what the estimand is\n",
    "    * which makes Luke Miratrix upset\n",
    "    * in our NY example, we get a strong effect\n",
    "* **Hypothesis testing**\n",
    "    * there is also interest in answering the question: is the treatment effect non-zero anywhere\n",
    "    * not necessarily answered by the average treatment effect: one section could have positive effect, and another negative\n",
    "    * one can use a chi-squared test to get at this\n",
    "    * but the covariance on the cliff face is often of low rank, if not mathematically, then computationally\n",
    "    * Benavoli and Mangili suggest a solution to this: remove eigenvalue below a certain threshold\n",
    "    * nu is the number of eigenvalues above epsilon\n",
    "    * in B&M, they have simulations that indicate that this test is conservative: under the null, p-value below 0.05 *less* than 5% of the time\n",
    "    * my simulations in this particular context show the same thing\n",
    "    * taking a frequentist stance, I've also looked at the distribution of this test-statistic under the null-hypothesis that the outcomes come from a single GP, and found that there is an extra component to the variance which accounts for this conservatism\n",
    "    * but I'm finding it difficult to reason about this test: a frequentist test that uses a Bayesian posterior as its test statistic\n",
    "* Pairwise comparisons\n",
    "    * going back to the NYC example\n",
    "    * long at each pair of adjacent school districts\n",
    "    * obtain the treatment effect cliff-face\n",
    "    * compute the average treatment effect using inverse-variance weights\n",
    "    * get a mean and variance\n",
    "    * compute the effect size mean / standard deviation\n",
    "    * plot border with that thickness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
