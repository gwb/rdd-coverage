{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev1 toc-item\"><a href=\"#Model-Specification\" data-toc-modified-id=\"Model-Specification-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model Specification</a></div><div class=\"lev2 toc-item\"><a href=\"#Notation\" data-toc-modified-id=\"Notation-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Notation</a></div><div class=\"lev2 toc-item\"><a href=\"#1GP-solution-[to-be-deleted]\" data-toc-modified-id=\"1GP-solution-[to-be-deleted]-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>1GP solution [to be deleted]</a></div><div class=\"lev2 toc-item\"><a href=\"#Gaussian-process-model\" data-toc-modified-id=\"Gaussian-process-model-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Gaussian process model</a></div><div class=\"lev2 toc-item\"><a href=\"#Inference\" data-toc-modified-id=\"Inference-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Inference</a></div><div class=\"lev2 toc-item\"><a href=\"#1GP-[to-be-deleted]\" data-toc-modified-id=\"1GP-[to-be-deleted]-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>1GP [to be deleted]</a></div><div class=\"lev1 toc-item\"><a href=\"#Handling-covariates\" data-toc-modified-id=\"Handling-covariates-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Handling covariates</a></div><div class=\"lev1 toc-item\"><a href=\"#Average-Treatment-Effect\" data-toc-modified-id=\"Average-Treatment-Effect-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Average Treatment Effect</a></div><div class=\"lev2 toc-item\"><a href=\"#Uniform-ATE\" data-toc-modified-id=\"Uniform-ATE-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Uniform ATE</a></div><div class=\"lev2 toc-item\"><a href=\"#Density-weighted-ATE\" data-toc-modified-id=\"Density-weighted-ATE-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Density weighted ATE</a></div><div class=\"lev2 toc-item\"><a href=\"#Inverse-variance-weighted-ATE\" data-toc-modified-id=\"Inverse-variance-weighted-ATE-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Inverse variance weighted ATE</a></div><div class=\"lev2 toc-item\"><a href=\"#Projected-Finite-population-ATE\" data-toc-modified-id=\"Projected-Finite-population-ATE-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Projected Finite-population ATE</a></div><div class=\"lev2 toc-item\"><a href=\"#Projected-land-ATE\" data-toc-modified-id=\"Projected-land-ATE-45\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Projected land ATE</a></div><div class=\"lev2 toc-item\"><a href=\"#Projected-superpopulation-ATE\" data-toc-modified-id=\"Projected-superpopulation-ATE-46\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Projected superpopulation ATE</a></div><div class=\"lev2 toc-item\"><a href=\"#Wiggly-Border-Simulation\" data-toc-modified-id=\"Wiggly-Border-Simulation-47\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Wiggly Border Simulation</a></div><div class=\"lev2 toc-item\"><a href=\"#Summary-of-Estimator-Properties\" data-toc-modified-id=\"Summary-of-Estimator-Properties-48\"><span class=\"toc-item-num\">4.8&nbsp;&nbsp;</span>Summary of Estimator Properties</a></div><div class=\"lev1 toc-item\"><a href=\"#Testing-for-non-zero-effect\" data-toc-modified-id=\"Testing-for-non-zero-effect-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Testing for non-zero effect</a></div><div class=\"lev2 toc-item\"><a href=\"#Using-the-inverse-variance-weighted-mean-treatment-effect-posterior-to-test-the-weak-null-hypothesis\" data-toc-modified-id=\"Using-the-inverse-variance-weighted-mean-treatment-effect-posterior-to-test-the-weak-null-hypothesis-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Using the inverse-variance weighted mean treatment effect posterior to test the weak null hypothesis</a></div><div class=\"lev2 toc-item\"><a href=\"#Likelihood-based-sharp-null-test\" data-toc-modified-id=\"Likelihood-based-sharp-null-test-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Likelihood-based sharp null test</a></div><div class=\"lev2 toc-item\"><a href=\"#“chi-squared”-test-for-the-sharp-null\" data-toc-modified-id=\"“chi-squared”-test-for-the-sharp-null-53\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>“chi-squared” test for the sharp null</a></div><div class=\"lev2 toc-item\"><a href=\"#Power-in-simulated-example\" data-toc-modified-id=\"Power-in-simulated-example-54\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Power in simulated example</a></div><div class=\"lev2 toc-item\"><a href=\"#Placebo-tests\" data-toc-modified-id=\"Placebo-tests-55\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Placebo tests</a></div><div class=\"lev1 toc-item\"><a href=\"#Spatial-advantage-[candidate-for-removal]\" data-toc-modified-id=\"Spatial-advantage-[candidate-for-removal]-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Spatial advantage [candidate for removal]</a></div><div class=\"lev1 toc-item\"><a href=\"#Example:-NYC-school-districts\" data-toc-modified-id=\"Example:-NYC-school-districts-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Example: NYC school districts</a></div><div class=\"lev2 toc-item\"><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-71\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Preprocessing</a></div><div class=\"lev2 toc-item\"><a href=\"#Exploratory-analysis\" data-toc-modified-id=\"Exploratory-analysis-72\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Exploratory analysis</a></div><div class=\"lev2 toc-item\"><a href=\"#Model-for-property-prices\" data-toc-modified-id=\"Model-for-property-prices-73\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Model for property prices</a></div><div class=\"lev2 toc-item\"><a href=\"#parameter-optimization\" data-toc-modified-id=\"parameter-optimization-74\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>parameter optimization</a></div><div class=\"lev2 toc-item\"><a href=\"#cliff-face\" data-toc-modified-id=\"cliff-face-75\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>cliff face</a></div><div class=\"lev2 toc-item\"><a href=\"#Average-Log-Price-Increase\" data-toc-modified-id=\"Average-Log-Price-Increase-76\"><span class=\"toc-item-num\">7.6&nbsp;&nbsp;</span>Average Log-Price Increase</a></div><div class=\"lev2 toc-item\"><a href=\"#Significant-Difference-in-Price?\" data-toc-modified-id=\"Significant-Difference-in-Price?-77\"><span class=\"toc-item-num\">7.7&nbsp;&nbsp;</span>Significant Difference in Price?</a></div><div class=\"lev3 toc-item\"><a href=\"#placebo-tests\" data-toc-modified-id=\"placebo-tests-771\"><span class=\"toc-item-num\">7.7.1&nbsp;&nbsp;</span>placebo tests</a></div><div class=\"lev2 toc-item\"><a href=\"#pairwise-treatment-effect-(all-districts)\" data-toc-modified-id=\"pairwise-treatment-effect-(all-districts)-78\"><span class=\"toc-item-num\">7.8&nbsp;&nbsp;</span>pairwise treatment effect (all districts)</a></div><div class=\"lev1 toc-item\"><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Conclusion</a></div><div class=\"lev1 toc-item\"><a href=\"#Covariances-in-2GP-model\" data-toc-modified-id=\"Covariances-in-2GP-model-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Covariances in 2GP model</a></div><div class=\"lev1 toc-item\"><a href=\"#Posterior-mean-of-hat\\beta\" data-toc-modified-id=\"Posterior-mean-of-hat\\beta-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Posterior mean of $\\hat\\beta$</a></div><div class=\"lev1 toc-item\"><a href=\"#Calibration-of-inverse-variance-test\" data-toc-modified-id=\"Calibration-of-inverse-variance-test-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Calibration of inverse-variance test</a></div><div class=\"lev1 toc-item\"><a href=\"#Wiggly-border-simulation-results\" data-toc-modified-id=\"Wiggly-border-simulation-results-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Wiggly border simulation results</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\newcommand{\\genericdel}[3]{%\n",
    "      \\left#1#3\\right#2\n",
    "    }\n",
    "    \\newcommand{\\del}[1]{\\genericdel(){#1}}\n",
    "    \\newcommand{\\sbr}[1]{\\genericdel[]{#1}}\n",
    "    \\newcommand{\\cbr}[1]{\\genericdel\\{\\}{#1}}\n",
    "    \\newcommand{\\abs}[1]{\\genericdel||{#1}}\n",
    "    \\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "    \\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "    \\DeclareMathOperator{\\Pr}{\\mathbb{p}}\n",
    "    \\DeclareMathOperator{\\E}{\\mathbb{E}}\n",
    "    \\DeclareMathOperator{\\Ind}{\\mathbb{I}}\n",
    "    \\DeclareMathOperator{\\V}{\\mathbb{V}}\n",
    "    \\DeclareMathOperator{\\cov}{Cov}\n",
    "    \\DeclareMathOperator{\\var}{Var}\n",
    "    \\DeclareMathOperator{\\ones}{\\mathbf{1}}\n",
    "    \\DeclareMathOperator{\\invchi}{\\mathrm{Inv-\\chi}^2}\n",
    "    \\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "    \\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "    \\newcommand{\\effect}{\\mathrm{eff}}\n",
    "    \\newcommand{\\xtilde}{\\widetilde{X}}\n",
    "    \\DeclareMathOperator{\\normal}{\\mathcal{N}}\n",
    "    \\DeclareMathOperator{\\unif}{Uniform}\n",
    "    \\newcommand{\\boxleft}{\\unicode{x25E7}}\n",
    "    \\newcommand{\\boxright}{\\unicode{x25E8}}\n",
    "    \\newcommand{\\discont}{\\unicode{x25EB}}\n",
    "    \\newcommand{\\jleft}{\\unicode{x21E5}}\n",
    "    \\newcommand{\\jright}{\\unicode{x21E4}}\n",
    "    \\DeclareMathOperator*{\\gp}{\\mathcal{GP}}\n",
    "    \\newcommand{\\trans}{^{\\intercal}}\n",
    "    \\newcommand{\\area}{\\mathcal{A}}\n",
    "    \\newcommand{\\treat}{\\mathrm{T}}\n",
    "    \\newcommand{\\ctrol}{\\mathrm{C}}\n",
    "    \\newcommand{\\treatind}{Z}\n",
    "    \\newcommand{\\treatarea}{\\area{}^{\\treat}}\n",
    "    \\newcommand{\\ctrolarea}{\\area{}^{\\ctrol}}\n",
    "    \\newcommand{\\sigmaf}{\\sigma_{\\mathrm{GP}}}\n",
    "    \\newcommand{\\sigman}{\\sigma_{\\epsilon}}\n",
    "    \\newcommand{\\sigmatau}{\\sigma_{\\tau}}\n",
    "    \\newcommand{\\sigmabeta}{\\sigma_{\\beta}}\n",
    "    \\newcommand{\\sigmamu}{\\sigma_{m}}\n",
    "    \\newcommand{\\sigmagamma}{\\sigma_{\\gamma}}\n",
    "    \\newcommand{\\svec}{\\mathbf{s}}\n",
    "    \\newcommand{\\vvec}{\\mathbf{v}}\n",
    "    \\newcommand{\\yvec}{\\mathbf{y}}\n",
    "    \\newcommand{\\muvec}{\\mathbf{\\mu}}\n",
    "    \\newcommand{\\indep}{\\perp}\n",
    "    \\newcommand{\\iid}{iid}\n",
    "    \\newcommand{\\vectreat}{Z}\n",
    "    \\newcommand{\\yt}{Y^\\treat}\n",
    "    \\newcommand{\\yc}{Y^\\ctrol}\n",
    "    \\newcommand{\\border}{\\mathcal{B}}\n",
    "    \\newcommand{\\sentinels}{\\mathbf{b}}\n",
    "    \\newcommand{\\eye}{\\mathbf{I}}\n",
    "    \\newcommand{\\K}{\\mathbf{K}}\n",
    "    \\DeclareMathOperator{\\trace}{trace}\n",
    "    \\newcommand{\\tauw}{\\tau^{w}}\n",
    "    \\newcommand{\\unifavg}{\\tau^{\\mathrm{UNIF}}}\n",
    "    \\newcommand{\\invvar}{\\tau^{\\mathrm{INV}}}\n",
    "    \\newcommand{\\taurho}{\\tau^{\\rho}}\n",
    "    \\newcommand{\\tauproj}{\\tau^{\\mathrm{PROJ}}}\n",
    "    \\newcommand{\\taugeo}{\\tau^{\\mathrm{GEO}}}\n",
    "    \\newcommand{\\taupop}{\\tau^{\\mathrm{POP}}}\n",
    "    \\newcommand{\\modnull}{\\mathscr{M}_0}\n",
    "    \\newcommand{\\modalt}{\\mathscr{M}_1}\n",
    "    \\newcommand{\\degree}{\\hspace{0pt}^\\circ}\n",
    "    % NYC %\n",
    "    \\newcommand{\\saleprice}{\\mathtt{SalePrice}}\n",
    "    \\newcommand{\\sqft}{\\mathtt{SQFT}}\n",
    "    \\newcommand{\\xvec}{\\mathbf{x}}\n",
    "    \\newcommand{\\dvec}{\\mathbf{d}}\n",
    "    \\newcommand{\\tax}{\\mathtt{TaxClass}}\n",
    "    \\newcommand{\\building}{\\mathtt{BuildingClass}}\n",
    "    \\newcommand{\\district}{\\mathtt{District}}\n",
    "    \\newcommand{\\eqlabel}[1]{\\label{#1}}\n",
    "    %\\renewcommand{\\eqref}[1]{(\\verbß#1ß)}\n",
    "    \\DeclareMathOperator{\\proj}{proj}\n",
    "    \\DeclareMathOperator{\\dif}{d}\n",
    "    \\newcommand{\\taubold}{\\mathbf{\\tau}}\n",
    "    \\DeclareMathOperator{\\Forall}{\\forall}\n",
    "    \\newcommand{\\numsent}{R}\n",
    "    \\newcommand{\\weightb}{w_{\\border}}\n",
    "    \\newcommand{\\wt}{w_{\\treat}}   \n",
    "    \\newcommand{\\wc}{w_{\\ctrol}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LaTeXStrings\n",
    "using GaussianProcesses\n",
    "using Distributions\n",
    "using Base.LinAlg\n",
    "using Distances\n",
    "import PyPlot; plt=PyPlot\n",
    "plt.rc(\"figure\", dpi=300.0)\n",
    "# plt.rc(\"figure\", figsize=(6,4))\n",
    "plt.rc(\"figure\", autolayout=true)\n",
    "plt.rc(\"savefig\", dpi=300.0)\n",
    "plt.rc(\"text\", usetex=true)\n",
    "plt.rc(\"font\", family=\"serif\")\n",
    "plt.rc(\"font\", serif=\"Palatino\")\n",
    ";"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\begin{abstract}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression discontinuity designs (RDDs) arise in observational studies when the treatment assignment is fully determined by a single “forcing” variable: all units on one side of a fixed threshold receive a treatment that the rest do not receive.\n",
    "More recently, situations with multiple forcing variables have garnered interest.\n",
    "When these variables are specifically spatial covariates, that is when a treatment is applied to a region but not its adjacent neighbor, the resulting natural experiment is termed a geographic regression discontinuity design (GeoRDD).\n",
    "In this paper, we propose a framework for analysing GeoRDDs, which can be understood as a spatial analog to the usual approach to RDDs, and which can be encapsulated in three steps: \n",
    "(1) fit a response surface to the outcomes in the adjacent regions, \n",
    "(2) extrapolate the two fitted surfaces to the border, and \n",
    "(3) take the difference of the two extrapolations to obtain an estimate of the treatment effect at each point along the border.\n",
    "We implement these steps by employing modeling tools from the spatial statistics literature, in particular kriging (Gaussian process regression).\n",
    "We then turn our attention to the definition and estimation of the average treatment effect along the border, and to hypothesis testing for GeoRDDs.\n",
    "We illustrate our methodology using publicly available house sale data from New York City,\n",
    "and show evidence of a discontinuity in price between neighboring school districts."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\end{abstract}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider an experiment performed on a population of units that are distributed geographically,\n",
    "in which a treatment gets applied to selected units, while the rest are used as a control group.\n",
    "For each unit, an outcome $Y_i$ is measured.\n",
    "If the treatment assignment is randomized, standard estimators from randomized control trials apply, such as the difference in observed means within the treatment and control groups.\n",
    "If outcomes vary spatially, it would be wise to match units that are near each other, in order to prevent this variation from confounding the estimate [a citation here would be nice].\n",
    "\n",
    "Now, we may find ourselves in a situation where the treatment does not get assigned at random. \n",
    "Instead, the land is arbitrarily divided into two contiguous regions, and the treatment is applied to units in one region, and withheld from those in the other.\n",
    "Ignoring the spatial covariates is particularly inadvisable in this scenario, as units in the two regions could be very different from each other.\n",
    "Matching is no longer directly applicable either, as there is no overlap in the spatial covariates.\n",
    "<cite data-cite=\"keele2015enhancing\">(Keele Titiunik 2015)</cite> develop a methodology to extend matching to GeoRDDs, by matching units across the border while minimizing the total sum of geographic distances between them.\n",
    "While sound, power is low because some units remain unmatched, and it requires a compromise between power and unbiasedness: matching units that are further away from the border reduces variance but introduces bias due to spatial variation.\n",
    "\n",
    "Examples of GeoRDDs situation occasionally appear in the literature. In <cite data-cite=\"macdonald2015effect\">(MacDonald, 2015)</cite>, a private police force patrols a neighborhood, but stays out of surrounding areas, and a causal effect on crime rates is sought. In  <cite data-cite=\"chen2013evidence\">(Chen, 2013)</cite>, a policy applies South of the Huai River in China but not in the North, and pollution levels and life expectancies are measured to infer environmental and health impacts of the policy.\n",
    "\n",
    "When treatment assignment is dictated by thresholding a single covariate (above or below the threshold all units are assigned to treatment, and all others to control), then the methodologies developed for regression discontinuity designs (RDD) enable the estimation of a causal effect despite the lack of overlap in the covariate. Our aim is to develop methodologies for our setting, which we recognize as geographic regression discontinuity designs <cite data-cite=\"keele_titiunik_2015\">(Keele, 2015)</cite>.\n",
    "\n",
    "Noticing this connection, practicioners often wish to use the well-established tools developed for one-dimensional RDDs for their spatial problem. \n",
    "Unfortunately, the most common methodologies, based on local linear regression on both sides of the border, do not extend naturally to two-dimensional settings.\n",
    "A temptation therefore arises to reduce a geographic RDD problem to a classical (one-dimensional) RDD by projecting locations onto the distance away from the border, an method that we will refer to as “projected RDD.”\n",
    "This is the approach taken by, for example, <cite data-cite=\"macdonald2015effect\">(MacDonald, 2015)</cite> and <cite data-cite=\"chen2013evidence\">(Chen, 2013)</cite>. We can illustrate the inappropriateness of this approach with a simple example. \n",
    "Suppose we have units in a 2D square, with spatial coordinates $\\svec_1 \\in [-1,1]$, and $\\svec_2 \\in [-1,1]$, and with a border at $s_1=0$ separating a treatment region from a control region.\n",
    "Let us assume the null hypothesis, with outcomes driven only by $\\svec_2$ (parallel to the border), given by $Y_{i} = \\alpha \\svec_{2i} + \\epsilon_i$,\n",
    "where $\\epsilon_i$ is an iid noise term $\\epsilon_i \\sim \\normal\\del{0, \\sigman^2}$.\n",
    "Lastly, let us consider the situation where the density $\\rho(\\svec)$ of units is different in each quadrant of the square:\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    \\rho(\\svec) = 2\\rho_0 & \\text{, where }\\svec_1 < 0,~\\svec_2 > 0 & \\text{ (top left)} \\\\\n",
    "    \\rho(\\svec) = \\rho_0 & \\text{, where }\\svec_1 > 0,~\\svec_2 > 0 & \\text{ (top right)} \\\\\n",
    "    \\rho(\\svec) = 2\\rho_0 & \\text{, where }\\svec_1 > 0,~\\svec_2 < 0 & \\text{ (bottom right)}  \\\\\n",
    "    \\rho(\\svec) = \\rho_0 & \\text{, where }\\svec_1 < 0,~\\svec_2 < 0 & \\text{ (bottom left)}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "The projection RDD then considers a univariate RDD along $s_1$.\n",
    "The usual RDD estimand \\eqref{eq:rdd_univ_estimand} can be obtained analytically, and equals $\\tau=\\frac{-\\alpha}{3}$, despite assuming the null hypothesis.\n",
    "This is because $s_2$ acts as a hidden confounder, whose distribution changes discontinuously at the border, which leads to bias and inconsistency in the projected univariate RDD estimate.\n",
    "In geographical settings, a discontinuous change in the density of units at the border is not unusual: for example a border could run alongside a park, or a small body of water, therefore with zero population density on one side of the border.\n",
    "A visual inspection of Figure \\ref{fig:sales_map} showing the locations of units in a New York City property sales dataset reveals many examples of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose a framework for analysing GeoRDDs that is directly analogous to their univariate counterpart, and avoids the need to project positions onto a single dimension. \n",
    "Univariate RDD methodologies can be abstracted to three steps:  \n",
    "\n",
    "1. Fit a smooth **function** to the outcomes against the covariate on each side of the discontinuity; \n",
    "2. Extrapolate the functions to the **discontinuity point** $x^*$; and \n",
    "3. Subtract the two extrapolations to estimate the treatment effect at the threshold point $\\tau(x^*) \\in \\mathbb{R}$.\n",
    "\n",
    "Reusing the same conceptual skeleton and applying it to geographical RDDs, our framework proceeds analogously:    \n",
    "\n",
    "1. Fit a smooth **surface** to the outcomes against the geographical covariates on each side of the discontinuity; \n",
    "2. Extrapolate the surfaces to the **border curve** $\\border$; and \n",
    "3. Subtract the two extrapolations to estimate the treatment effect along the border $\\tau(\\svec): \\border \\rightarrow \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While local linear regression is commonly used to fit and extrapolate the smooth response functions in RDDs, we propose to use kriging (Gaussian process regression) to fit the response surfaces in GeoRDDs.\n",
    "This is motivated by the well-established use of kriging for fitting smoothly varying spatial processes in the spatial statistics literature.\n",
    "See <cite data-cite=\"banerjee2014hierarchical\">(Banerjee, 2014)</cite> for a textbook introduction to kriging for spatial data, and <cite data-cite=\"rasmussen2006gaussian\">(Rasmussen and Williams, 2006)</cite> for a machine learning perspective on Gaussian process regression.\n",
    "The application of Gaussian process regression to univariate RDDs is presented in <cite data-cite=\"Branson:2017qy\">(Branson 2017)</cite>, with encouraging results compared to local linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a point estimate in the RDD case, the GeoRDD framework gives a functional estimate $\\tau(\\svec)$, defined on an irregular one-dimensional manifold (the border) that is embedded in two dimensional space (the surface of the Earth), and that is more challenging to interpret.\n",
    "Subsequently, analysts might often be interested in summarizing the information contained in the functional estimand.\n",
    "In section \\ref{sec:ate}, we explore possible estimands for the average treatment effect (ATE), and elucidate their respective pitfalls and advantages.\n",
    "In section \\ref{sec:hypothesis_testing}, we turn to hypothesis testing, and propose methods to test against the null hypothesis of no treatment effect.\n",
    "We also suggest Placebo tests \\[cite?\\] to examine the validity of the hypothesis tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Specification\n",
    "\n",
    "## Notation\n",
    "\n",
    "We largely adopt the setup and notation for geographic regression discontinuity designs laid out in <cite data-cite=\"keele_titiunik_2015\">(Keele, 2015)</cite>. \n",
    "$n$ units are observed within an area $\\area$ of 2-dimensional coordinate space.\n",
    "The $n$ units are divided into $n_\\treat$ “treatment” units in area $\\treatarea \\subset \\area$\n",
    "and $n_\\ctrol$ units in the control area $\\ctrolarea$.\n",
    "The defining characteristic of the regression discontinuity design is that the two areas are adjacent but non-overlapping, so $\\treatarea \\cap \\ctrolarea = \\emptyset$ and $\\treatarea \\cup \\ctrolarea = \\area$.\n",
    "In the potential outcomes framework, we imagine that each unit $i$ has a potential outcome under treatment $Y_{i\\treat}$ and a potential outcome under control $Y_{i\\ctrol}$.\n",
    "The unit's treatment indicator $\\treatind_i$ is 1 if the unit is in the treatment group, and 0 in control.\n",
    "Unlike traditional randomized experiments, the treatment assignment is a deterministic function of the unit's location $\\svec_i$, $\\treatind_i = \\Ind\\cbr{\\svec_i \\in \\treatarea}$.\n",
    "The observed outcome can be written as $Y_i = \\treatind_i Y_{i\\treat} + (1 - \\treatind_i) Y_{i\\ctrol}$.\n",
    "\n",
    "The border between $\\treatarea$ and $\\ctrolarea$ is denoted $\\border$.\n",
    "But for computational reasons, we will often represent the border as a set $\\sentinels$ of $\\numsent$ “sentinel” points along the border, with each $\\sentinels_i \\in \\border$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1GP solution [to be deleted]\n",
    "\n",
    "Most straightforwardly, we model the observed outcome $Y_i$ at location $\\svec_i$ as the sum of an intercept $\\mu$, linear trend with coefficients $\\beta$, a spatial Gaussian process $f(\\svec)$, a constant treatment effect $\\tau$ in the treatment region, and iid normal noise $\\epsilon$.\n",
    "\n",
    "\\begin{equation}\\begin{split}\n",
    "Y_i &= \\mu+\\svec_i\\trans\\beta + f(\\svec_i) + \\tau \\treatind_i + \\epsilon_i \\\\\n",
    "f &\\sim \\gp\\del{0, k(\\svec, \\svec')} \\\\\n",
    "k(\\svec,\\svec') &= \\sigmaf^2 \\exp\\del{ - \\frac{\\del{\\svec-\\svec'}\\trans\\del{\\svec-\\svec'}}{2 \\ell^2}} \\\\\n",
    "\\epsilon_i &\\overset{\\iid}{\\sim} \\normal\\del{0,\\sigma_\\epsilon^2}\n",
    "\\end{split}\\end{equation}  \n",
    "$f$ is a smooth surface covering all of $\\area$, specificed as a Gaussian Process with squared exponential covariance kernel $k$ with lengthscale $\\ell$ and variance $\\sigmaf^2$.\n",
    "The squared exponential kernel is frequently used in spatial settings to model smoothly varying quantities.\n",
    "This model implies a constant treatment effect assumption $Y_{i\\treat} = \\tau + Y_{i\\ctrol}$ for all units at all locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian process model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\label{sec:twogp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper, we propose to use Gaussian process regression (GPR), also known as kriging in the spatial statistics literature, to fit the outcomes on either side of the border.\n",
    "GPR is a Bayesian non-parametric method for fitting smooth functions, that was shown by <cite data-cite=\"Branson:2017qy\">(Branson 2017)</cite> to be a powerful method for fitting univariate RDDs.\n",
    "Further inspired by the popularity of GPR in spatial statistics, we extend the model and method of <cite data-cite=\"Branson:2017qy\">(Branson 2017)</cite> to geographical RDDs.\n",
    "\n",
    "On each side of the border, we model the observed outcomes $Y_i$ at location $\\svec_i$ as the sum of an intercept $m$, linear trend with coefficients $\\beta$, a spatial Gaussian process $f(\\svec)$, and iid normal noise $\\epsilon$. \n",
    "The Gaussian process has zero mean, and its covariance function is a modeling choice.\n",
    "There is a rich literature of possible covariance functions (“kernels” in the machine learning world) **[LukeB: do you have a good reference summarizing popular options?]**, but in this paper, we will use the squared exponential kernel, for its ease of understanding and its prevalence in applied spatial statistics.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "Y_{i\\treat} &= \\underbrace{m_\\treat{} + \\svec_i\\trans\\beta_\\treat{} + f_\\treat{}(\\svec_i)}_{g_\\treat{}(\\svec_i)} + \\epsilon_i \\\\\n",
    "Y_{i\\ctrol} &= \\underbrace{m_\\ctrol{} + \\svec_i\\trans\\beta_\\ctrol{} + f_\\ctrol{}(\\svec_i)}_{g_\\ctrol{}(\\svec_i)} + \\epsilon_i \\\\\n",
    "f_\\treat{}, f_\\ctrol{} &\\overset{\\indep}{\\sim} \\gp\\del{0, k(\\svec, \\svec')} \\\\\n",
    "k(\\svec,\\svec') &= \\sigmaf^2 \\exp\\del{ - \\frac{\\del{\\svec-\\svec'}\\trans\\del{\\svec-\\svec'}}{2 \\ell^2}}\n",
    "\\end{split}\n",
    "\\eqlabel{eq:spec2gp}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the treatment effect $\\tau$ is not included explicitly in the model. Instead, the treatment effect at a location $\\svec$ is derived as the difference between the two (noise-free) surfaces $g_\\treat{}$ and $g_\\ctrol{}$.\n",
    "\\begin{equation}\n",
    "\\tau(\\svec) = \\sbr{m_\\treat{} + \\svec\\trans\\beta_\\treat{} + f_\\treat{}(\\svec)} - \\sbr{m_\\ctrol{} + \\svec\\trans\\beta_\\ctrol{} + f_\\ctrol{}(\\svec)}\n",
    "\\end{equation}\n",
    "\n",
    "In this specification, the parameters $\\ell$, $\\sigmaf$, and $\\sigman$ are the same in the treatment and control regions, so we assume that the spatial smoothness of the responses isn't affected by the treatment. \n",
    "We expect that this assumption will be reasonable in many applications, but it can be easily relaxed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We proceed by placing normal priors on $m_\\treat$, $m_\\ctrol$ and $\\beta$. \n",
    "The model specification \\eqref{eq:spec2gp} can then be used to obtain covariances between the observations and these parameters. \n",
    "In fact, $\\del{Y_{\\ctrol},Y_{\\treat},f_{\\treat},f_{\\ctrol},m_{\\ctrol},m_{\\treat},\\beta_{\\treat}, \\beta_{\\ctrol}} \\mid \\ell,\\sigmaf, \\sigman$ is multi-variate normal, and so the distribution of any variable conditioned on the others can be obtained analytically and easily computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[I think the estimand should be made clear before the model is introduced (move up)]**\n",
    "\n",
    "Because the treatment and control regions do not overlap, inference on the treatment effect is only measurable near the border. In the classical one-dimensional regression discontinuity design, the estimand is therefore defined at the border $x=b$: \n",
    "\\begin{equation}\n",
    "\\eqlabel{eq:rdd_univ_estimand}\n",
    "\\tau = \\lim_{x \\downarrow b} \\E\\sbr{y \\mid X=s} - \\lim_{x \\uparrow b} \\E\\sbr{y \\mid X=x} = \\E\\sbr{Y_{i\\treat} \\mid X_i=b} - \\E\\sbr{Y_{i\\ctrol} \\mid X_i=b}\n",
    "\\end{equation}\n",
    "Analogously, we focus on the treatment effect at the border $\\border$ between the treatment and control regions, as defined in <cite data-cite=\"imbens2011regression\">(Imbens and Zajonc, 2011)</cite> and <cite data-cite=\"keeleoverview\">(Keele and Lorch, 2017)</cite>.\n",
    "\\begin{equation}\n",
    "\\tau: \\border \\rightarrow \\mathbb{R},\\,\\tau(\\sentinels) =  \\E\\sbr{Y_{i\\treat} - Y_{i\\ctrol} \\mid \\svec_i = \\sentinels}\n",
    "\\eqlabel{eq:functional_estimand}\n",
    "\\end{equation}\n",
    "Note that $\\border$ is a one-dimensional manifold embedded in $\\area$. \n",
    "We proceed by extrapolating both Gaussian processes to the border, \n",
    "and then taking the difference of the predictions to obtain the posterior treatment effect $\\tau(\\border)$ along the border. \n",
    "Computationally, we need to represent this border as a set of $\\numsent$ “sentinel” units distributed along the border $\\sentinels=\\cbr{\\sentinels_1,\\ldots,\\sentinels_{\\numsent}},~\\sentinels_i \\in \\border$. \n",
    "The extrapolation step then proceeds mechanically through multivariate-normal theory.\n",
    "\\begin{equation}\\begin{split}\n",
    "    g_\\treat{}(\\sentinels) \\mid Y_\\treat{}, S_\\treat{}, \\ell, \\sigmaf, \\sigman &\\sim \\normal\\del{\\mu_{\\sentinels \\mid T}, \\Sigma_{\\sentinels \\mid T}} \\\\\n",
    "    \\mu_{\\sentinels \\mid T} &\\equiv \\cov\\del{g_\\treat{}(\\sentinels), Y_\\treat{}} \\cov\\del{Y_\\treat{}}^{-1}  Y_\\treat{} \\\\\n",
    "    \\Sigma_{\\sentinels \\mid T} &\\equiv \\cov \\del{g_\\treat{}(\\sentinels)} - \\cov\\del{g_\\treat{}(\\sentinels), Y_\\treat{}} \\cov\\del{Y_\\treat{}}^{-1} \\cov\\del{Y_\\treat{},g_\\treat{}(\\sentinels)\n",
    "    }\n",
    "\\end{split}\n",
    " \\label{eq:postvar2gp_t_or_c}\n",
    "\\end{equation}\n",
    "with all the covariance matrices derived from the model specification. \n",
    "Analogously predictions for $g_\\ctrol{}(\\sentinels)$ are obtained using the data in the control region, and denote their posterior mean and covariance as $\\mu_{\\sentinels \\mid C}$ and $\\Sigma_{\\sentinels \\mid C}$. Since the two surfaces are modeled as independent, the treatment effect $\\tau(\\sentinels)=g_\\treat{}(\\sentinels)-g_\\ctrol{}(\\sentinels)$ along the border is also multivariate normal with posterior mean and covariance\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    \\mu_{\\sentinels \\mid Y} &= \\E \\del{\\tau(\\sentinels) \\mid Y_\\treat{}, Y_\\ctrol{}} = \\mu_{\\sentinels \\mid \\treat} - \\mu_{\\sentinels \\mid \\ctrol} \\\\\n",
    "    \\Sigma_{\\sentinels \\mid Y} &= \\cov\\del{\\tau(\\sentinels) \\mid Y_\\treat{}, Y_\\ctrol{}} = \\Sigma_{\\sentinels \\mid \\treat} + \\Sigma_{\\sentinels \\mid \\ctrol}\\,.\n",
    "\\end{split}\n",
    "\\eqlabel{eq:postvar2gp}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1GP [to be deleted]\n",
    "\n",
    "By modeling the spatial variation using Gaussian processes, we can leverage the properties of multivariate normals to obtain analytical forms for the estimate of the treatment effect.\n",
    "\n",
    "We proceed by placing normal priors on $\\mu$, $\\beta$ and $\\tau$. The model specification can then be used to obtain covariances between the observations and these parameters. In fact, $\\del{Y,\\tau,\\mu,\\beta} \\mid \\ell,\\sigmaf, \\sigman$ is multi-variate normal with variance-covariance given by\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    \\tau  &\\sim \\normal\\del{0,\\sigmatau^2} \\\\\n",
    "    \\mu   &\\sim \\normal\\del{0,\\sigmamu^2} \\\\\n",
    "    \\beta &\\sim \\normal\\del{0,\\sigmabeta^2} \\\\\n",
    "    \\cov(Y_i,\\tau) &= \\sigmatau^2 Z_i \\\\\n",
    "    \\cov(Y_i,\\mu)  &= \\sigmamu^2 \\\\\n",
    "    \\cov(Y_i,\\beta)&= \\sigmabeta^2 \\svec\\trans \\svec \\\\\n",
    "    \\cov(Y_i,Y_j)&= \\sigmamu^2 + \\sigmatau^2 Z_i Z_j + \\sigmabeta^2 \\svec_i\\trans \\svec_j + k(\\svec_i,\\svec_j) + \\delta_{ij}\\sigman^2\\\\\n",
    "    \\cov(Y_i,f(\\svec_j)) &= \\cov(f(\\svec_i),f(\\svec_j)) = k(\\svec_i,\\svec_j)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "Multi-variate normal theory then allows us to condition any of these variables on the others. We are particularly interested in the posterior distribution $\\tau \\mid Y, \\ell, \\sigmaf, \\sigman$ which is given by\n",
    "\\begin{equation}\n",
    "    \\tau \\mid Y, \\ell, \\sigmaf \\sim \\normal\\del{\\cov\\del{Y,\\tau}\\trans \\cov\\del{Y}^{-1} Y, \\sigma_\\tau^2 - \\cov\\del{Y,\\tau}\\trans \\cov\\del{Y}^{-1} \\cov\\del{Y,\\tau}}\n",
    "\\end{equation}\n",
    "\n",
    "To proceed computationally, we define the treatment indicator vector $\\vectreat$ with $i$th entry equal to $Z_i$, the spatial covariate $n \\times 2$ matrix $S$ with $i$th row $\\svec_i$, and the $n \\times n$ kernel covariance matrix $\\K$ having entries $\\K_{ij}=k(\\svec_i, \\svec_j)$. The posterior mean and variance are then easily computed.\n",
    "\n",
    "\\begin{equation}\\begin{split}\n",
    "    \\E \\del{\\tau \\mid Y, \\ell, \\sigmaf, \\sigman} &= \\sigmatau^2 \\vectreat\\trans \\cbr{\\sigmamu^2 + \\sigmatau^2 \\vectreat \\vectreat\\trans + \\sigmabeta^2 S S\\trans + \\K + \\sigman^2 \\eye }^{-1} Y \\\\\n",
    "    \\var \\del{\\tau \\mid Y, \\ell, \\sigmaf, \\sigman} &= \\sigma_\\tau^2 - \\sigma_\\tau^2 \\vectreat\\trans \\cbr{\\sigmamu^2 + \\sigmatau^2 \\vectreat \\vectreat\\trans + \\sigmabeta^2 S S\\trans + \\K + \\sigman^2 \\eye }^{-1} \\vectreat\n",
    "\\end{split}\\end{equation}\n",
    "\n",
    "What remains is the inference on the hyperparameters $\\sigman, \\sigmaf$ and $\\ell$. The two approaches typically taken in modern spatial statistics are either to maximize the marginal likelihood of $Y$ as a function of those three parameters, or to assign them a prior and take a Bayesian approach, requiring that the posterior of $\\tau$ be integrated over those parameters. The compromise is clear: the Bayesian approach incorporates the uncertainty in the hyperparameters, thus giving more reliable inference on $\\tau$, but maximizing the marginal likelihood has a much lower computation cost. Therefore, we recommend taking the Bayesian approach whenever computationally possible, and maximizing the marginal likelihood when the data is larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling covariates\n",
    "\n",
    "The Gaussian Process specification makes it easy to incorporate a linear model on non-spatial covariates, both mathematically and computationally. \n",
    "The models are modified by the addition of the linear regression term $D \\gamma$ on the $n \\times p$ matrix of covariates $D$. In the spirit of ridge regression, we recommend placing a normal prior $\\normal(0,\\sigmagamma^2)$ on the regression coefficients. This preserves the multivariate normality of the model, with the simple addition of a term $\\sigmagamma^2 D\\trans D$ to the covariance of $Y$. \n",
    "\n",
    "Our model becomes\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "Y_{i\\treat} &= \\underbrace{m_\\treat{} + \\dvec_i\\trans \\gamma + \\svec_i\\trans\\beta_\\treat{} + f_\\treat{}(\\svec_i)}_{g_\\treat{}(\\svec_i)} + \\epsilon_i \\\\\n",
    "Y_{i\\ctrol} &= \\underbrace{m_\\ctrol{} + \\dvec_i\\trans \\gamma + \\svec_i\\trans\\beta_\\ctrol{} + f_\\ctrol{}(\\svec_i)}_{g_\\ctrol{}(\\svec_i)} + \\epsilon_i \\\\\n",
    "f_\\treat{}, f_\\ctrol{} &\\overset{\\indep}{\\sim} \\gp\\del{0, k(\\svec, \\svec')} \\\\\n",
    "k(\\svec,\\svec') &= \\sigmaf^2 \\exp\\del{ - \\frac{\\del{\\svec-\\svec'}\\trans\\del{\\svec-\\svec'}}{2 \\ell^2}} \\\\\n",
    "\\gamma_j &\\overset{\\indep}{\\sim} \\normal\\del{0,\\sigmagamma^2}\\text{ for }j=1,2,\\ldots,p\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "Unfortunately, the linear term induces a covariance between the treatment and control region.\n",
    "When the two regions are independent, fitting the Gaussian processes required the inversion of an $n_\\treat{} \\times n_\\treat{}$ covariance matrix, and of an $n_\\ctrol{} \\times n_\\ctrol{}$ matrix.\n",
    "But with the additional covariates, the covariance of $Y$ is no longer block diagonal. \n",
    "Thus the inversion of an $(n_\\treat{}+n_\\ctrol{}) \\times (n_\\treat{}+n_\\ctrol{})$ is now required.\n",
    "Matrix inversion algorithms generally have computational complexity $O(n^3)$.\n",
    "Therefore, if the units are evenly split between the two regions,\n",
    "the overall complexity of the model fitting increases fourfold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Treatment Effect"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\label{sec:ate}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we obtain the posterior on the treatment effect function $\\tau(\\border)$, estimating the average treatment effect (ATE) along the border will often be of interest. \n",
    "We consider the class of weighted means of the functional treatment effect $\\tau\\del{\\svec}$,\n",
    "with weight function $\\weightb(\\svec)$ defined everywhere on the border $\\border$.\n",
    "The weighted mean integral can be approximated as a sum at the sentinels $\\sentinels_{1:\\numsent}$.\n",
    "\\begin{equation}\\begin{split}\n",
    "    \\tauw &= \\frac{\\oint_\\border \\left. \\weightb(\\svec) \\tau(\\svec) \\dif \\svec \\right.}\n",
    "                  {\\oint_\\border \\left. \\weightb(\\svec) \\dif \\svec \\right.}\\,,\\\\\n",
    "          &\\approx \\frac{\\sum_{i=0}^\\numsent \\weightb(\\sentinels_i) \\tau(\\sentinels_i)}\n",
    "                       {\\sum_{i=0}^\\numsent \\weightb(\\sentinels_i) } \\,.\n",
    "\\end{split}\n",
    "\\eqlabel{eq:weighted_estimand}\n",
    "\\end{equation}\n",
    "We have shown the posterior distribution of $\\tau(\\svec)$ at the sentinels to be multivariate normal, with mean $\\mu_{\\sentinels \\mid Y}$ and covariance $\\Sigma_{\\sentinels \\mid Y}$ given in \\eqref{eq:postvar2gp}.\n",
    "Since $\\tauw$ is a linear transformation of $\\tau(\\sentinels)$, its posterior is also multivariate normal, with mean $\\mu_{\\tauw \\mid Y}$ and covariance $\\Sigma_{\\tauw \\mid Y}$ given by\n",
    "\\begin{equation}\\begin{split}\n",
    "    \\mu_{\\tauw \\mid Y} &= \\frac{\\weightb(\\sentinels)\\trans \\mu_{\\sentinels \\mid Y}}\n",
    "                               {\\weightb(\\sentinels)\\trans  \\ones_\\numsent} \\\\\n",
    "    \\Sigma_{\\tauw \\mid Y} &= \\frac{\\weightb(\\sentinels)\\trans \\Sigma_{\\sentinels \\mid Y} \\weightb(\\sentinels)}\n",
    "                                  { \\del{\\weightb(\\sentinels)\\trans  \\ones_\\numsent }^2 }\\\\\n",
    "\\end{split}\n",
    "\\eqlabel{eq:weighted_estimator}\n",
    "\\end{equation}\n",
    "where $\\weightb(\\sentinels)$ is the vector of weights evaluated at the sentinels.\n",
    "For each estimator obtained in \\eqref{eq:weighted_estimator} as a weighted mean of $\\mu_{\\sentinels \\mid Y}$, we consider the “natural” estimand to be the same weighted mean applied to the truth $\\tau(\\svec)$, given by \\eqref{eq:weighted_estimand}.\n",
    "\n",
    "An alternative perspective on these estimators is given by the weights induced on the observations.\n",
    "Indeed, combining equations \\eqref{eq:postvar2gp_t_or_c}, \\eqref{eq:postvar2gp}, and \\eqref{eq:weighted_estimator}, we obtain that the posterior mean of $\\tauw$ is a linear combination \n",
    "\\begin{equation}\n",
    "\\E\\del{\\tauw \\mid Y} = \\wt\\trans Y_\\treat + \\wc\\trans Y_\\ctrol\n",
    "\\eqlabel{eq:unit_weights}\n",
    "\\end{equation}\n",
    "of the observed data, with “unit weights” given by \n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\wt &= \\frac{1}{\\weightb(\\sentinels)\\trans \\ones_{\\numsent}}\n",
    "K_{\\treat \\treat}^{-1} K_{\\treat \\sentinels} \\weightb(\\sentinels) \\,, \\text{ and}\n",
    "\\\\\n",
    "\\wc &= -\\frac{1}{\\weightb(\\sentinels)\\trans \\ones_{\\numsent}} \n",
    "K_{\\ctrol \\ctrol}^{-1} K_{\\ctrol \\sentinels} \\weightb(\\sentinels) \\,,\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "for treatment and control units respectively.\n",
    "\n",
    "The question remains: what is the most appropriate choice of weights? In this section, we motivate and consider six possibilities choices of $\\weightb(\\svec)$, and explore interpretation, advantages, and disadvantages.\n",
    "The six border weight functions and unit weights for a simulated example are shown in Figure \\ref{fig:weight_functions}(a-f).\n",
    "Interestingly, the projected RDD estimator can also be written in the form \\eqref{eq:unit_weights}, and so we also illustrate the resulting unit weights in Figure \\ref{fig:weight_functions}(g)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform ATE\n",
    "\n",
    "The simplest choice is uniform weights $\\weightb(\\svec)=1$, a seemingly reasonable and unopinionated decision.\n",
    "We estimate $\\unifavg$, the uniformly weighted mean of $\\tau(\\svec)$ along the border, by averaging the entries of the mean posterior at the sentinels. \n",
    "Following \\eqref{eq:weighted_estimand} and \\eqref{eq:weighted_estimator}:\n",
    "\\begin{equation}\\begin{split}\n",
    "    \\unifavg &\\equiv \\frac{\\oint_\\border \\left. \\tau(x) \\dif \\svec \\right.}\n",
    "                          {\\oint_\\border \\left. \\dif x \\right.} \\\\\n",
    "    \\unifavg \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\ell &\\sim \\normal\\del{\\mu_{\\unifavg \\mid Y}, \\Sigma_{\\unifavg \\mid Y}} \\\\\n",
    "    \\mu_{\\unifavg \\mid Y} &= \\del{\\ones\\trans \\mu_{\\sentinels \\mid Y}} / \\numsent \\\\\n",
    "    \\Sigma_{\\unifavg \\mid Y} &= \\del{\\ones\\trans \\Sigma_{\\sentinels \\mid Y} \\ones} / \\numsent^2\n",
    "\\end{split}\n",
    "\\eqlabel{eq:unifavg}\n",
    "\\end{equation}\n",
    "Note that if the sentinels are not evenly spaced, then each entry needs to be re-weighted by the length of the border that the sentinel occupies.\n",
    "The uniformly weighted estimand takes on a geometric interpretation: equal-length segments of the border are given equal weight.\n",
    "The procedure is mathematically sound, but the choice of this estimator suffers from issues that we describe and address in the next two sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density weighted ATE\n",
    "\n",
    "With uniform border weights, parts of the border adjoining dense populations are given equal weights to those in sparsely populated areas. \n",
    "But if the border goes through an unpopulated area, like a lake or a public park, then the treatment effect there has little meaning and importance. \n",
    "Furthermore, $\\tau(\\svec)$ in those empty areas will have large posterior variances, which will dominate the posterior variance of $\\unifavg$, potentially jeopardizing the successful detection of otherwise strong treatment effects: $\\unifavg$ will drown them in noise.\n",
    "\n",
    "We can address this issue by weighting the treatment effect at each sentinel location by the local density.\n",
    "That is we choose $\\weightb(\\svec) = \\rho(\\svec)$, where $\\rho$ is the local population density.\n",
    "The resulting estimand $\\taurho$ also has an attractive interpretation as population-based rather than geometry-based. \n",
    "It gives equal weights to units of the superpopulation who live on the border rather than to lengths of the border,\n",
    "and it therefore better captures the “typical” treatment effect received by a unit.\n",
    "This is the estimand used by <cite data-cite=\"keele_titiunik_2015\">(Keele, 2015)</cite>, who themselves follow in the footsteps of <cite data-cite=\"imbens2011regression\">(Imbens and Zajonc, 2011)</cite>.\n",
    "\n",
    "In practice, the local density needs to be estimated.\n",
    "A simple kernel density estimator can be used, \n",
    "though one could also deploy a more sophisticated spatial point process model.\n",
    "Strictly speaking, the uncertainty of the local density estimate should then be propagated to the estimate of $\\taurho$, which may therefore no longer have a normally distributed or analytically tractable posterior. \n",
    "These inconveniences certainly reduce the appeal of the density-weighted estimator,\n",
    "but there is a deeper issue affecting this choice of estimand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse variance weighted ATE\n",
    "\n",
    "![\\label{fig:mississippi_counts} Evenly spaced sentinels along the border between Mississippi and Louisiana.](../figures/mississippi_counts.png)\n",
    "\n",
    "The unweighted and density-weighted mean treatment estimands are subtly affected by the shape of the border between the treatment and control regions,\n",
    "giving higher weight to wigglier sections of the border.\n",
    "We illustrate this with the border separating two American States: Louisiana and Mississippi.\n",
    "From North to South, the border follows the meandering Mississippi river, then takes a sharp turn to the East and becomes a straight line, until it meets the even more sinuous Pearl river, which it then follows until it reaches the Gulf of Mexico. \n",
    "Sentinels placed at equal distance intervals along this border will therefore be more densely packed along the rivers, and sparsest along the straight segment (see Figure \\ref{fig:mississippi_counts}).\n",
    "When averaging a function over the border, those sections will therefore be overrepresented. \n",
    "Troublingly, the sinuousness of the border therefore determines the estimand,  \n",
    "even though the outcomes of interest will generally have nothing to do with river topologies.\n",
    "In population terms, the result is that units near wigglier segments receive more weight.\n",
    "Worse, the resolution of the map used in the analysis affects the estimated ATE.\n",
    "\n",
    "This unwelcome dependence of the $\\unifavg$ estimand on the border topology is a symptom of the geometry of the problem: the 1-dimensional treatment function $\\tau(\\border)$ is embedded in a Euclidean 2-dimensional space.\n",
    "The dependencies induced by this geometric fact are reflected in the covariance $\\Sigma_{\\sentinels \\mid Y}$: sentinels in the straight segment of the border will be less strongly correlated than in the sinuous segments. \n",
    "The more correlated sentinels individually carry less information about the local treatment effect. \n",
    "Instead of averaging the posterior treatment effect along the border based on geometry or population, we consider averaging the information contained therein. \n",
    "This motivates the use of the inverse-variance weighted mean $\\invvar$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    \\left. \\invvar \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\ell \\right. &\\sim \\normal\\del{\\mu_{\\invvar \\mid Y}, \\Sigma_{\\invvar \\mid Y}} \\,, \\\\\n",
    "    \\mu_{\\invvar \\mid Y} &= \\del{\\ones\\trans \\Sigma_{\\sentinels \\mid Y}^{-1} \\mu_{\\sentinels \\mid Y}} \\big/ \\del{\\ones\\trans \\Sigma_{\\sentinels \\mid Y}^{-1} \\ones} \\,, \\\\\n",
    "    \\Sigma_{\\invvar \\mid Y} &= 1 \\big/ \\del{\\ones\\trans \\Sigma_{\\sentinels \\mid Y}^{-1} \\,. \\ones}\n",
    "\\end{split}\n",
    "\\eqlabel{eq:invvar}\n",
    "\\end{equation}\n",
    "This estimator efficiently extracts the information from the posterior treatment effect, and is guaranteed to yield the lowest posterior variance amongst weighted averages of the form \\eqref{eq:weighted_estimand}.\n",
    "It automatically gives more weight to sentinels in dense areas (as the variance will be lower there), and to sentinels in straight sections of the border.\n",
    "The approach is in keeping with the philosophy of regression discontinuity designs: we let information be our guide when weighting the mean treatment effect, just like it guided the  regression discontinuity design to only focus on the treatment effect at the border. \n",
    "This estimand isn't chosen by the scientist, but rather it is dictated by the limitations of the observed data.\n",
    "\n",
    "The estimand is still a weighted mean, with weights for the sentinels given by $\\weightb(\\sentinels) = \\Sigma_{\\sentinels \\mid Y}^{-1} \\ones$.\n",
    "This can put negative weights on some sentinels, as seen for example in Figure \\ref{fig:weight_functions}(c), and generally this estimand doesn't lend itself to an intuitive scientific interpretation.\n",
    "This is counter to the conventional wisdom in causal inference, that the estimand should be chosen based on substantive grounds, ideally before collecting any data.\n",
    "While unorthodox in the causal inference literature, analogous “estimands of convenience” have been proposed in other settings, for example matching methods that exclude some unmatched units from the analysis, or <cite data-cite=\"li2016balancing\">(Li 2016)</cite> in the context of balancing treatment and control populations with little overlap in their covariate distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projected Finite-population ATE\n",
    "\n",
    "All average treatment effect estimators considered so far presuppose evenly spaced sentinel points, which are then given weights.\n",
    "Alternatively, we can project the positions of treatment and control units onto the border, and use those projected sentinel positions without weights.\n",
    "In the spirit of a finite-population estimate, each unit figuratively gets one vote, though instead of a direct vote, it has a representative at the border.\n",
    "For any points $\\svec$, we use the notation $\\proj_{\\border}\\del{\\svec}$ to give the coordinates of the point on the border $\\border$ that is closest to $\\svec$ (assuming uniqueness).\n",
    "The projected finite-population $\\tauproj$ is then the uniformly weighted mean applied with the projected sentinels instead of the evenly spaced sentinels.\n",
    "We can therefore modify \\eqref{eq:unifavg}, replacing the cliff-face mean vector $\\mu_{\\sentinels \\mid Y}$\n",
    "and covariance matrix $\\Sigma_{\\sentinels \\mid Y}$\n",
    "with equivalent quantities obtained at the projected sentinels, \n",
    "to obtain the posterior mean and covariance of $\\tauproj$:\n",
    "\\begin{equation}\\begin{split}\n",
    "    \\tauproj \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\ell &\\sim \\normal\\del{\\mu_{\\tauproj \\mid Y}, \\Sigma_{\\tauproj \\mid Y}}\\,, \\\\\n",
    "    \\mu_{\\tauproj \\mid Y} &= \\frac{1}{n_\\ctrol{} + n_\\treat{}} \\sum_{i=1}^{n_\\treat{}+n_\\ctrol{}} \n",
    "        \\E\\sbr{\n",
    "            \\tau\\del{\n",
    "                \\proj_{\\border}\\del{\\svec_i}\n",
    "            }\n",
    "            \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\ell\n",
    "         } \\,,\\\\\n",
    "    \\Sigma_{\\tauproj \\mid Y} &= \\frac{1}{\\del{n_\\ctrol{} + n_\\treat{}}^2}\n",
    "        \\sum_{i=1}^{n_\\treat{}+n_\\ctrol{}} \n",
    "        \\sum_{j=1}^{n_\\treat{}+n_\\ctrol{}} \n",
    "        \\cov\\sbr{\n",
    "            \\tau\\del{\n",
    "                \\proj_{\\border}\\del{\\svec_i}\n",
    "            },\n",
    "            \\tau\\del{\n",
    "                \\proj_{\\border}\\del{\\svec_j}\n",
    "            }\n",
    "            \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\ell\n",
    "        }\\,.\n",
    "\\end{split}\n",
    "\\eqlabel{eq:tauproj}\n",
    "\\end{equation}\n",
    "The posterior expectations and covariances in \\eqref{eq:tauproj} can be obtained as in \\eqref{eq:postvar2gp}, but using the projected sentinels.\n",
    "Note that $\\tauproj$ is still within the class of weighted mean estimands \\eqref{eq:weighted_estimand}, \n",
    "with weight function $\\weightb(\\svec) = \\sum_{i=1}^{n_\\treat{}+n_\\ctrol{}} \\delta\\del{ \\svec - \\proj_\\border(\\svec_i)}$, where $\\delta$ is the Dirac delta function.\n",
    "\n",
    "The resulting estimator has desirable properties: densely populated regions receive proportionately more sentinels, but wigglier segments of the border do not.\n",
    "While it lacks the information efficiency of the inverse-variance estimator,\n",
    "the projected estimand is much easier to understand and interpret,\n",
    "and may feel more familiar to practicioners used to finite-population inference.\n",
    "\n",
    "If there are units very far away from the border, \n",
    "they may be deemed irrelevant for the purposes of the analysis of a regression discontinuity design. In that case, only those units within a certain distance of the border (e.g. one or two lengthscales of the fitted Gaussian process) should be projected onto the border to become sentinels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projected land ATE\n",
    "\n",
    "In certain applications, estimands that depend on the position of measurements are undesirable, and geography-weighted estimands are more natural. **[LukeB: Citation? Better sentence?]**\n",
    "The “geometry-based” unweighted estimand $\\unifavg$ has the property that each segment of the border has equal weight.\n",
    "If instead, we desire each patch of land to have equal weight, we can borrow the projection method from $\\tauproj$ and apply it to an infinite population of uniform density on both sides of the border.\n",
    "This yields the geography-based projected land ATE $\\taugeo$.\n",
    "To estimate $\\taugeo$, a tight grid of evenly spaced points is first generated within $\\treatarea$ and $\\ctrolarea$.\n",
    "Each point on this grid is then projected onto the border and becomes a sentinel.\n",
    "The 2GP procedure applied to these unevenly spaced sentinels then yields a mean vector and covariance matrix for the treatment effect at these positions.\n",
    "The mean of the mean vector then gives an estimate of $\\taugeo$.\n",
    "In other words, $\\taugeo$ is estimated by applying the $\\unifavg$ estimator with sentinels obtained by projecting the grid points, instead of equispaced sentinels.\n",
    "$\\taugeo$ remains in the category of weighted-mean estimands, with the weight function $\\weightb(\\svec)$ in \\eqref{eq:weighted_estimand} proportional to the area of $\\treatarea$ and $\\ctrolarea$ that $\\svec$ is nearest to:\n",
    "\\begin{equation}\n",
    "\\weightb(\\svec) = \\int_{\\area} \\left. \\Ind \\cbr{\\svec = \\proj_{\\border}\\del{\\svec'}} \\dif \\svec' \\right.\n",
    "\\end{equation}\n",
    "\n",
    "[**Note:** this integral is not strictly correct, since the area closest to a point on the border can be infinitesimal (for example in the case of a straight border. Suggestions for better notation welcome.]\n",
    "\n",
    "Again, if land far away from the border is deemed irrelevant to the analysis, the grid should be restricted to within a certain distance of the border.\n",
    "This can be achieved in GIS software by obtaining a buffer around the border, then intersecting the resulting polygon with the grid points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projected superpopulation ATE\n",
    "\n",
    "Lastly, the purely geographical estimand $\\taugeo$ can be modified by weighing the grid points by the population density at that location.\n",
    "This gives the projected superpopulation ATE $\\taupop$.\n",
    "Similarly to the density-weighted ATE $\\taurho$, estimating $\\taupop$ requires an estimate of the density $\\rho(\\svec)$ at every point covered by the grid.\n",
    "Strictly speaking, the uncertaining in the estimate of $\\rho$ should be propagated to the estimate of $\\taupop$, which generally will make the posterior distribution of $\\taupop$  neither normal nor analytically tractable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiggly Border Simulation\n",
    "\n",
    "We illustrate the differences between the four average treatment effect estimators with a simulation.\n",
    "200 units are placed in a square area delimited by spatial coordinates $S_1 \\in \\cbr{0,2}$ and $S_2 \\in \\cbr{-1, 1}$.\n",
    "A border at $S_2=0$ divides units vertically into a control and treatment region,\n",
    "which are then further divided horizontally at $S_1=0.5$ and $S_1=1.5$ into three bands:\n",
    "\n",
    "* The leftmost band $S_1 < 0.5$ has a weak treatment effect.\n",
    "* The middle band $0.5 \\ge S_1 < 1.5$ has a much lower population density, and a stronger treatment effect.\n",
    "* The rightmost band $S_1 \\ge 1.5$, has a much higher population density, and a very strong treatment effect.\n",
    "\n",
    "Furthermore, the border in the leftmost band is a triangular wave, to create “wiggliness.”\n",
    "We increase the number of wiggles from 0 to 1000 to observe the effect on the estimates.\n",
    "The simulation setting is summarized in Table \\ref{table:wiggly_setup}. \n",
    "The outcomes $Y$ are simulated from a Gaussian process with squared exponential kernel \n",
    "($\\ell=0.4$, $\\sigma=0.5$), to which we add a treatment effect $\\tau(S_1, S_2) = S_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                 | Left $s_1< 0.5$ | Middle $0.5 \\ge s_1 < 1.5$ | Right $1.5 \\ge s_1$ |\n",
    "|----------------:|-----------------|----------------------------|---------------------|\n",
    "|      **Border** | wiggly          | straight                   | straight            |\n",
    "|     **Density** | low $\\rho=1.0$  | very low $\\rho=0.3$        | high $\\rho=2.0$     |\n",
    "| $\\taubold$ | weak            | medium                     | strong              |\n",
    "Table: Summary of wiggly border simulation setup. \\label{table:wiggly_setup}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\\label{fig:wiggly_boundaries} (a) Spatial positions of units and border; (b) Estimator (posterior mean) and estimand (dotted lines of same color) behavior as left border gets wigglier; (c) Posterior standard deviation for each estimator as left border gets wigglier. **(no plot in bottom left yet, final layout TBD)**](../figures/wiggly_boundaries.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\\label{fig:weight_functions}Weight functions and induced weights on the observations for the six weight functions proposed in this paper. The weight function plots show the weight $\\weightb(\\sentinels)$ against each sentinel's $S_1$ coordinate. Sentinels with equal $S_1$ positions were merged and their weights summed. The induced weight plots show a circle for each unit, with the area of the circle proportional to its weight ($\\wt$ and $\\wc$), and colored in blue for positive weights and orange for negative weights.\n",
    "](../figures/weight_functions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit Gaussian processes on each side of the border, \n",
    "using the known hyperparameters and constant mean equal to the empirical mean,\n",
    "and estimate the average treatment effect using the six methods proposed above.\n",
    "The simulation setting is illustrated in Figure \\ref{fig:wiggly_boundaries}(a).\n",
    "For each estimator, we show in Figure \\ref{fig:wiggly_boundaries}(b) the estimand and posterior mean estimate evolving as the number of wiggles increases.\n",
    "The behavior of the posterior standard deviation is shown in Figure \\ref{fig:wiggly_boundaries}(c).\n",
    "\n",
    "As the border is a straight line and $\\treatarea$ and $\\ctrolarea$ are rectangles,\n",
    "and as the treatment effect does not depend on the vertical axis $S_2$, \n",
    "the density-weighted estimand $\\taurho$ equals the projected superpopulation estimand $\\taupop$,\n",
    "and they are in fact both equal to the infinite-population average treatment effect.\n",
    "Correspondingly, the posteriors of $\\taurho$ and $\\taupop$ are identical.\n",
    "With 200 units, the finite-population and the infinite-population projected estimands are similar, though the difference can be more pronounced with smaller sample populations.\n",
    "\n",
    "The geometry- and geography-based ATE $\\unifavg$ and $\\taugeo$ are also equivalent when the border is a straight line.\n",
    "They give equal weight to the sparsely populated middle band, which produces a lower estimate with higher variance than the posteriors of $\\taurho$ and $\\taupop$.\n",
    "\n",
    "Lastly, the information-based inverse-variance estimand $\\invvar$ does not coincide with any others.\n",
    "However, $\\invvar$ is guaranteed to have the lowest posterior variance within the class of ATEs under consideration, which can indeed be seen in Figure \\ref{fig:wiggly_boundaries}(c).\n",
    "\n",
    "As we introduce wiggles into the leftmost band,\n",
    "$\\taurho$ and $\\unifavg$ show their susceptibility to the border topology.\n",
    "Proportionally more sentinels are packed into the leftmost section of the border,\n",
    "upweighting the lower treatment effect of that band,\n",
    "and resulting in a drop of the two estimates and estimands.\n",
    "Meanwhile, $\\invvar$ remains stable despite the wiggles, \n",
    "because the additional sentinels in the leftmost\n",
    "band get automatically downweighted as their correlation rises.\n",
    "The estimators that rely on projection \n",
    "$\\tauproj$, $\\taugeo$, and $\\taupop$  also remain stable, \n",
    "because the projected sentinels hardly move.\n",
    "These robust estimands show only a slight displacement when the first wiggles are introduced,\n",
    "caused by the presence of some sentinels nearer to the observed units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Figure \\ref{fig:weight_functions}, we illustrate the behavior of border weights ($\\weightb(\\svec)$) and unit weights ($\\wt$ and $\\wc$) in this simulation setting with 3 wiggles.\n",
    "Note that all estimators can give some small negative weights to treatment units, and small positive weights to control units.\n",
    "For Gaussian processes, this can be understood in terms of the negative side-lobes of the equivalent kernel (see <cite data-cite=\"rasmussen2006gaussian\">(Rasmussen and Williams 2006)</cite> section 2.6).\n",
    "For local linear regression, it results from the negative influence on the prediction $\\widehat{y^*}$ at $x^*$ that univariate linear regression can give to an observation $Y_i$ at $X_i$ sufficiently far away on the opposite side of the mean $\\overline{X}$ of all observations.\n",
    "The high variance of $\\unifavg$ and $\\taugeo$ manifests itself as large weights given to a small number of units. \n",
    "All other estimators spread the weights more evenly amongst the units near the border, which reduces their variance.\n",
    "We also see how more sentinels are packed into the leftmost area because of the zig-zagging border.\n",
    "The inverse-variance weighted estimator border weights can be seen to respond to this change in the border topology, though it is difficult to interpret their oscillating behavior.\n",
    "While these border-weights look unreasonable and unstable, the induced unit weights are actually well-behaved, and in fact quite similar to those of the projected finite- and infinite-population estimators.\n",
    "\n",
    "\n",
    "The weights placed on units by the projected RDD are shown in Figure \\ref{fig:weight_functions}(g).\n",
    "A triangular kernel in $S_2$ was used with bandwidth chosen using the MSE-minimizing method proposed by <cite data-cite=\"imbens2012optimal\">(Imbens and Kalyanaraman 2012)</cite>.\n",
    "By construction, the weights drop to zero outside of the support of the kernel.\n",
    "Strikingly, almost all of the positive weights are given to units in the rightmost treatment area that are closest to the border, and almost all the negative weights are given to units in the leftmost control area.\n",
    "Consequently, any trend in the outcomes across $S_1$ will confound the estimated treatment effect.\n",
    "\n",
    "In most applications, we recommend the use of the finite population or inverse-variance-weighted estimators, to prevent the undesirable influence of border topology.\n",
    "The projected finite population method is simplest to understand and interpret in the tradition of finite population estimators, and unlike the projected superpopulation estimator $\\taupop$ it does not require estimating population density.\n",
    "Meanwhile, the inverse-variance estimator is the most efficient (lowest posterior variance) weighted mean estimator,\n",
    "and avoids the potential complication of the choice of a distance cutoff for projected units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Estimator Properties\n",
    "\n",
    "| Symbol     | Description                     | Border Topology | Sentinels       | Principle         | Variance |\n",
    "|------------|---------------------------------|-----------------|-----------------|-------------------|----------|\n",
    "| $\\unifavg$ | Uniform ATE                     | Sensitive       | Equispaced      | Geometry-based    | High     |\n",
    "| $\\taurho$  | Density-weighted ATE            | Sensitive       | Equispaced      | Population-based  | Low      |\n",
    "| $\\invvar$  | Inverse-variance weighted ATE   | Robust          | Equispaced      | Information-based | Lowest   |\n",
    "| $\\tauproj$ | Projected finite population ATE | Robust          | Projected Units | Finite-population | Low      |\n",
    "| $\\taugeo$  | Projected land ATE              | Robust          | Projected Grid  | Geography-based   | High     |\n",
    "| $\\taupop$  | Projected superpopulation ATE   | Robust          | Projected Grid  | Population-based  | Low      |\n",
    "Table: Summary of average treatment effect estimtor and estimand properties. \\label{table:estimator_properties}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for non-zero effect"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\label{sec:hypothesis_testing}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the 2GP procedure, we might naturally wonder whether we can claim to have detected a significant treatment effect anywhere along the border. \n",
    "In the hypothesis testing framework, we have two possible choices of null hypotheses. \n",
    "The **sharp null** specifies that the treatment effect is zero everywhere along the border:\n",
    "$\\tau(\\border)=0$, \n",
    "while the **weak null** only requires the average treatment effect to be zero.\n",
    "\n",
    "## Using the inverse-variance weighted mean treatment effect posterior to test the weak null hypothesis\n",
    "\n",
    "As we saw in the previous section, the “average” treatment effect can be defined in multiple ways.\n",
    "If we choose the inverse-variance weighted mean, then $\\invvar$ has posterior given by \\eqref{eq:invvar}.\n",
    "While the posterior is a Bayesian object, we can use it heuristically to derive a pseudo-$p$-value\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    Z_0 &\\sim \\normal\\del{0, \\Sigma_{\\invvar \\mid Y}}  \\\\\n",
    "    p^{\\mathrm{INV}} &= \\Pr\\del{ \n",
    "        \\abs{Z_0} > \n",
    "        \\abs{\n",
    "            \\mu_{\n",
    "                \\invvar \\mid Y\n",
    "            }\n",
    "        } \n",
    "    } \\\\\n",
    "    &= 2\\Phi\\del{-\n",
    "        \\frac{\n",
    "            \\abs{\n",
    "                \\mu_{\n",
    "                    \\invvar \\mid Y\n",
    "                }\n",
    "            }\n",
    "        }{\n",
    "            \\sqrt{\n",
    "                \\Sigma_{\\invvar \\mid Y}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "This “p-value” obtained from the Bayesian posterior may not have good frequentist properties. In particular, there is no guarantee that under the null hypothesis, $p^{\\mathrm{INV}}$ is below 0.05 less than 5% of the time. We elaborate on this below after we demonstrate the behavior of this test in a simulated example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood-based sharp null test\n",
    "\n",
    "We can also target the sharp null hypothesis.\n",
    "We first create a null model $\\modnull$, \n",
    "specified as a single Gaussian process spanning the control and treatment regions, \n",
    "with the same kernel and hyperparameters obtained in the 2GP procedure. \n",
    "$\\modnull$ is smooth and continuous at the border,\n",
    "and therefore accords with the sharp null hypothesis.\n",
    "Intuitively, if there is a treatment effect, \n",
    "the likelihood of the observations should be lower under $\\modnull$ than under $\\modalt$, \n",
    "the 2$\\gp$ model as specified in equation \\eqref{eq:spec2gp}.\n",
    "We therefore choose the difference in log-likelihoods as our test statistic\n",
    "\\begin{equation}\n",
    "    t = \\log \\Pr\\del{Y_\\treat{}, Y_\\ctrol{} \\mid \\modalt} - \\log \\Pr\\del{Y_\\treat{}, Y_\\ctrol{} \\mid \\modnull}\n",
    "\\end{equation}\n",
    "and wish to reject the sharp null hypothesis when its observed value $t_{obs}$ is high.\n",
    "\n",
    "A parametric bootstrap approach is used to quantify what “high” means. We draw $Y_\\treat{}^*,Y_\\ctrol{}^*$ from $\\modnull$, \n",
    "using the same spatial locations as in the original data, \n",
    "and then fit the two competing models to the simulated data in order to obtain the bootstrapped test statistic\n",
    "\\begin{equation}\n",
    "    t^* = \\log \\Pr\\del{Y_\\treat{}^*, Y_\\ctrol{}^* \\mid \\modalt} - \\log \\Pr\\del{Y_\\treat{}^*, Y_\\ctrol{}^* \\mid \\modnull}\n",
    "\\end{equation}\n",
    "Repeating this procedure, we obtain a distribution of $t$ under $\\modnull$, \n",
    "which we can then compare to the observed $t$.\n",
    "More precisely, we can interpret the proportion of $t^*$ drawn above $t_{obs}$ as a $p$-value.\n",
    "\\begin{equation}\n",
    "    p^{\\mathrm{lik}} = \\Pr\\del{t^* > t_{obs} \\mid \\modnull}\n",
    "\\end{equation}\n",
    "Computationally, because the hyperparameters and locations of the units are held constant during the bootstrap, we can reuse the Cholesky decomposition of the covariance matrix, allowing the test to be performed in seconds even with hundreds of units and thousands of bootstrap samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## “chi-squared” test for the sharp null\n",
    "\n",
    "The likelihood-based sharp null above is valid and easy to understand.\n",
    "But it may seem odd that the test aims to detect a non-zero treatment effect at the border, without any explicit reference to the border $\\border$. The test statistic and $p$-values can be computed without access to the sentinel positions, using only the treatment and control indicators. If the test is significant, there is no guarantee that this is due to a discontinuity at the border.\n",
    "\n",
    "To address this oddity, we can derive a test statistic directly from the posterior treatment effect along the border, \n",
    "approximated in \\eqref{eq:postvar2gp} by its mean vector $\\muvec_{\\sentinels \\mid Y}$ \n",
    "and covariance matrix $\\Sigma_{\\sentinels \\mid Y}$ at the sentinel positions $\\sentinels$.\n",
    "We will use $\\muvec$ and $\\Sigma$ as shorthand throughout this section.\n",
    "If a $k$-vector $\\yvec$ has multivariate distribution $\\normal\\del{\\muvec, \\Sigma}$, with mean vector $\\muvec$ known and covariance $\\Sigma$ known, then under the null hypothesis that $\\mu=0$, the test statistic $\\yvec\\trans \\Sigma^{-1} \\yvec$ has distribution $\\chi^2_k$.\n",
    "See for example <cite data-cite=\"rencher2003methods\">(Rencher, 2003)</cite> section 5.2.2 for a classical derivation of this test.\n",
    "This suggests that we could use $S^2=\\muvec\\trans \\Sigma^{-1} \\muvec$ as a test statistic, \n",
    "and obtain a $p$-value from a $\\chi^2_\\numsent$ distribution function evaluated at $S^2$, where $\\numsent$ is the number of sentinels. \n",
    "However, we face two problems.\n",
    "Firstly, this test obtained heuristically from a Bayesian posterior, by analogy with the classical multivariate normal result, is not a valid frequentist test.\n",
    "Secondly, while $\\Sigma$ is mathematically full-rank, it is typically numerically rank-deficient.\n",
    "Therefore, $\\numsent$ overestimates the true degrees of freedom of the null distribution.\n",
    "\n",
    "Benavoli and Mangili (2015), developing a test for function equality, address the second problem by trimming the $\\Sigma$ eigenvalues $\\lambda_i$ lower than $\\epsilon \\sum_{j=1}^k \\lambda_j$, with $\\epsilon$ a pre-specified small number (they use 0.01).\n",
    "They address the first problem by showing that the resulting $p$-value is always conservative in their simulations. \n",
    "However, in our work, we found the resulting $p$-value to be sensitive to the arbitrarily chosen  $\\epsilon$ tolerance parameter, which makes it difficult to trust its validity.\n",
    "\n",
    "We therefore again take the parametric bootstrap approach, this time using $S^2$ as the test statistic instead of the likelihood ratio.\n",
    "With B bootstrap samples, the $p$-value is obtained as\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    p &= \\frac{1}{B} \\sum_{t=1}^T \\Ind\\cbr{S_{(b)}^2 < S^2}\\,,\\\\\n",
    "    S_{(b)}^2 &= \\del{ \\muvec_{(b)} }\\trans \\Sigma^{-1} \\muvec_{(b)}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "where $\\muvec_{(b)}$ is the result of applying \\eqref{eq:postvar2gp} to $Y_\\treat^{(b)}$ and $Y_\\ctrol^{(b)}$, themselves drawn from $\\modnull$ at the same locations as the observations $Y_\\treat$ and $Y_\\ctrol$.\n",
    "\n",
    "Because calculating $S^2$ involves inverting a matrix $\\Sigma$ that is mathematically of full rank, but numerically of low rank, we may worry about the numerical stability of computing $S$.\n",
    "We verified in simulated examples that regularizing $\\Sigma$ by adding a small constant to its diagonal does not greatly affect the computed $S^2$.\n",
    "The parametric bootstrap ensures the frequentist validity of the test\n",
    "regardless of the regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power in simulated example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\\label{fig:mississippi_counties}Set-up of the imaginary experiment in Louisiana and Mississippi. Each unit is at the centroid of a county. The colors indicated the observed outcomes in one draw of the simulation under $\\tau=1.5$. In this particular run, the p-values were 0.0016, 0.0018, and 0.0013 for the mLL, $\\chi^2$, and inverse-variance test respectively.](../figures/mississippi_sim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three tests we developed leverage different aspects of the problem, and target two different null hypotheses. One may wonder how their power compares in the presence of a treatment effect. Considering once more the border between Louisiana and Mississippi, we imagine an experiment where the unit of analysis is the county, located at its centroid, as shown in Figure \\ref{fig:mississippi_counties}. \n",
    "We will simulate outcomes from a single Gaussian Process covering both states. For simplicity, we fix the hyperparameters to arbitrary values: $\\sigman=\\sigmaf=1.0$ and $\\ell=100\\,\\mathrm{km}$. \n",
    "We then add a constant treatment effect $\\tau$ to all the outcomes in Louisiana.\n",
    "The results of the three tests proposed so far are shown in the first three rows of Table \\ref{table:power} for $\\tau=0$ (null hypothesis) and $\\tau=1.5$ and significance level $\\alpha=0.05$."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\begin{table}\n",
    "    \\caption{Power of marginal likelihood, chi-squared, and inverse-variance tests, with nominal significance of $\\alpha=0.05$, under null and alternative hypothesis for simulated outcomes at the centroids of Louisiana and Mississippi counties.}\n",
    "    \\label{table:power}\n",
    "    \\centering\n",
    "    \\begin{tabular}{rrr}\n",
    "        \\toprule\n",
    "        & \\multicolumn{2}{c}{Power under} \\\\\n",
    "        Test & $\\tau=0$ & $\\tau=1.5$ \\\\\n",
    "        \\midrule\n",
    "        Marginal log-likelihood $ $ & 0.050 & 0.935 \\\\\n",
    "        $\\chi^2$ & 0.051 & 0.878 \\\\\n",
    "        inverse-variance $\\Sigma^{-1}$ & 0.067 & 0.971 \\\\\n",
    "        bootstrap-calibrated $\\Sigma^{-1}$ & 0.052 & 0.962 \\\\\n",
    "        analytically-calibrated $\\Sigma^{-1}$ & 0.051 & 0.962 \\\\\n",
    "        \\bottomrule\n",
    "    \\end{tabular}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that under the null, the $\\chi^2$ and likelihood ratio tests are valid (rejection of the null in 5% of simulations up to simulation error).\n",
    "This is enforced by the parametric bootstrap, which draws test statistics from the same null distribution to calibrate the tests.\n",
    "However, the $p$-values for the inverse-variance test are biased down, so that we will falsely reject the null $6.7\\%$ instead of $5\\%$ of the time.\n",
    "While unfortunate, this is unsurprising, since the inverse-variance test was derived heuristically rather than from a rigorous frequentist procedure.\n",
    "To make it valid, it can be calibrated using the same parametric bootstrap approach that was used for the likelihood and $\\chi^2$ tests.\n",
    "The calibration can also be achieved analytically, since $\\mu_{\\invvar \\mid Y}$ is normally distributed under the null hypothesis.\n",
    "We derive the analytical calibration of the inverse-variance test in Appendix \\ref{sec:calibration}.\n",
    "\n",
    "After the calibration, the hypothesis test based on the inverse-variance mean still has higher power to detect the constant treatment effect than the mLL and $\\chi^2$ tests.\n",
    "This can lead to a paradox: we may reject the weak null hypothesis, but fail to reject the sharp null hypothesis (using the $\\chi^2$ or likelihood test), even though rejection of the weak null should logically imply rejection of the sharp null.\n",
    "This paradox isn't specific to this setting, and is discussed in depth in the context of randomization-based inference by <cite data-cite=\"Ding:2014sf\">(Ding, 2014)</cite>. Therefore, in studies where the main interest is an overall (average) increase or decrease in outcomes, we recommend using the inverse-variance test to maximize power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placebo tests"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\label{sec:placebo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Process models are almost always misspecified. \n",
    "We do not believe that the Gaussian process with stationary squared exponential kernel is the true data-generating process, although we hope that the model is sufficiently flexible to represent reality well.\n",
    "Under misspecification, we should be skeptical of results that rely on the truth of the model specification.\n",
    "We therefore encourage practicioners to probe the validity of the above hypothesis tests by running a “placebo” test.\n",
    "A placebo test repeatedly applies the hypothesis test on data that are known to have zero treatment effect (a “placebo”),\n",
    "in order to verify that the returned p-values are uniformly distributed.\n",
    "In our spatial setting, we will use the treatment and control regions separately as placebo groups.\n",
    "Within each placebo group, we repeatedly draw an arbitrary geographical border, creating new treatment and control groups.\n",
    "Because the border was chosen arbitrarily by us, we should not expect there to be a discontinuous jump in outcomes at this border.\n",
    "We then apply the bootstrapped likelihood test procedure described above to this arbitrarily divided data, store the results, and hope to obtain a roughly uniform distribution of p-values.\n",
    "In our implementation, we drew lines that split the placebo units in half at a sequence of angles $1\\degree,2\\degree,3\\degree,\\ldots,180\\degree$.\n",
    "The resulting p-values will obviously be highly correlated, so we should only expect a very roughly uniform distribution (because of the small effective sample size), but at the very least, this procedure allows us to visually verify that the p-values are not blatantly biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial advantage [candidate for removal]\n",
    "\n",
    "Classical regression discontinuity designs often suffer from low power, requiring many units near the border for inference to be possible. \n",
    "In the spatial RDD setting, we might worry that the situation is worse, as geographical datasets with many units packed along the border are uncommon. \n",
    "In geographical settings, each unit (e.g. household or counties) normally takes up space, so there is a limit to how densely packed units can be near the border. \n",
    "And boundaries often include sparsely populated segments, e.g. running through parks, industrial areas, or farmland. \n",
    "The intuition that spatial RDDs will therefore suffer from low power is correct, inasmuch as at any given point along the border, the posterior variance of $\\tau(\\border)$ will typically be high. \n",
    "But once we pool the information into an average treatment effect, or perform a sharp test, spatial RDDs can be more powerful than classical RDDs, with the same number of units at the same distance from the border.\n",
    "\n",
    "We illustrate this statement once more with the Louisiana-Mississippi example.\n",
    "The variance of the inverse-variance weighted treatment effect $\\invvar$ is thence only a function of the positions of the units, available analytically by plugging the posterior variance \\eqref{eq:postvar2gp} into the inverse-variance estimator \\eqref{eq:invvar}. \n",
    "Following this procedure, we obtain a posterior standard deviation of the average treatment effect of 0.31. \n",
    "We then create a one-dimensional regression discontinuity design for the same setting, by using each unit's distance from the border as the covariate $x$, the distribution of which is shown in Figure \\ref{fig:mississippi_counties}(b). \n",
    "Following the exact same 2GP procedure with the same hyperparameters as in the spatial setting, and with a discontinuity at $x=0$, we again compute the posterior standard deviation of the treatment effect at the border (now a single number rather than a continuous function) , this time obtaining 0.58. \n",
    "This higher figure indicates that, perhaps counter-intuitively, the spatial experiment actually has more power than its one-dimensional analog.\n",
    "\n",
    "To gain intuition about the higher power of the spatial RDD, we turn to the interpretation of regression discontinuity designs as natural experiments [need reference]. \n",
    "Near the discontinuity, we can reasonably claim that the side of the discontinuity that each unit fell into was largely dictated by random noise in the covariate. \n",
    "This in turn allows us to claim that a natural randomized experiment took place near the border, with treatment and control units coming from the same population. \n",
    "We can extend this interpretation to the spatial setting, by conceiving of multiple correlated experiments taking place all along the border. \n",
    "The average treatment effect estimator then pools the information supplied by all of these experiments.\n",
    "The question then becomes: do we get more powerful inference by grouping all the units into a single experiment, or by spreading them along a multitude of weaker experiments?\n",
    "There are two sources of uncertainty in our model: the observation noise $\\epsilon_i$, and the underlying processes $g_\\treat{}$ and $g_\\ctrol{}$. Adding more units to a single experiment allows us to cancel out more of the observation noise, but if the new units aren't added closer to the discontinuity, uncertainty always remains in $g_\\treat{}$ and $g_\\ctrol{}$. In the spatial setting, however, we observe multiple realizations of the Gaussian process, and therefore do not suffer from the same diminishing returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: NYC school districts\n",
    "\n",
    "We illustrate the analysis of geographical regression discontinuity designs using house sales data from New York City. \n",
    "The city publishes information pertaining to property sales within the city in the last twelve months on a rolling basis. \n",
    "This includes the sale price, building class, and the address of the property.\n",
    "Public schools in the city are all part of the City School District of the City of New York, but the city-wide district is itself divided into 32 sub-districts.\n",
    "Within these districts, schools also have attendance zones, and children living within a zone are guaranteed attendance in their zone school unless the school is full [is this true? [insideschools.com gives a more complete picture](http://insideschools.org/elementary/how-to-apply)].\n",
    "It is commonly held [could cite [this article at cityrealty.com](https://www.cityrealty.com/nyc/market-insight/features/trending-in-ny/buying-renting-school-zone-district-what-you-need-know/3661)] that school districts therefore have an impact on real estate price, as parents are willing to pay more to live in districts with better schools. \n",
    "We therefore ask: can we measure a discontinuous jump in house prices across school district boundaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "In order to model the property sale prices with a stationary Gaussian process, we need to obtain their location on a Euclidean grid. We geocode the address of each sale by merging the sales with NYC's Pluto database, which contains X and Y coordinates for each house, identified by its borough, zip code, block and lot. These coordinates are given in the `EPSG:2263` projection in units of feet. We use this projection throughout this example. For addresses that do not find a match in Pluto, we use google's geocoding API to obtain a latitude and longitude, which we then project to `EPSG:2263`.\n",
    "\n",
    "We then filter the sales data as follows, by removing\n",
    "1. sales of properties without a reported sale price\n",
    "1. sales of properties outside of the residential building class categories (“one family dwellings”, “two family dwellings”, “three family dwellings”, “tax class 1 condos”, “coops - walkup apartments”, “coops - elevator apartments”, “condos - walkup apartments”, “condos - elevator apartments”, “condos - 2-10 unit residential”, “condo coops\"),\n",
    "2. any sale with missing data in the sale price, square footage, property covariates, geographical coordinates (due to failed geocoding),\n",
    "3. sales outside of any NYC school district,\n",
    "4. properties smaller than 100 sq ft, and\n",
    "5. outliers in the price per square foot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "![\\label{fig:sales_map}sales map](../NYC/NYC_plots/NYC_sales.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for property prices\n",
    "\n",
    "The outcome of interest is price per square foot. As is often done in the real estate literature, we take its logarithm to reduce the skew of the outcome. The complete model is then a Gaussian Process over the geographical covariates $\\svec$ super-imposed with a linear regression on the property covariates (building and tax class). Within a school district we could write the model as [suggestions for clearer notation welcome]:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    Y_i &= \\log\\del{ \\frac{\\saleprice_i}{\\sqft_i}} =\n",
    "        \\begin{split}\n",
    "             \\mu_{\\district\\sbr{i}} + \\beta_{1,\\tax\\sbr{i}} + \\beta_{2,\\building\\sbr{i}} \\\\\n",
    "                  + f_{\\district\\sbr{i}}(\\svec_i) + \\epsilon_i \\\\\n",
    "         \\end{split}\n",
    "    \\\\\n",
    "    \\epsilon_i &\\sim \\normal\\del{0, \\sigma_y^2} \\\\\n",
    "    \\mu_{j} &\\sim \\normal\\del{\\bar{Y}_j, \\sigma_\\mu^2} \\\\\n",
    "    \\beta_{1j},\\beta_{2j} &\\sim \\normal\\del{0, \\sigma_\\beta^2} \\\\\n",
    "    f_j(\\svec_i) &\\sim \\gp\\del{0, k(\\svec, \\svec')} \\\\\n",
    "    k(\\svec, \\svec') &= \\sigmaf^2 \\exp\\cbr{ - \\frac{(\\svec-\\svec')\\trans(\\svec-\\svec')}{2\\ell^2}}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "A visual inspection of the house sales map above suggests examining the border between districts 19 and 27. Importantly, the border between the two districts is also part of the border between Brooklyn and Queens, so we won't be able to attribute a causal effect solely to the difference in school districts. We are first and foremost *measuring* a discontinuity in the house prices at the district. Attributing the discontinuity to a particular cause (school district or borough) is an interpretation that is not directly supported by the data.\n",
    "A histogram of $Y$ in both districts also shows that marginally the house prices are very different.\n",
    "Our goal is to establish that this difference is measurable at the border, and not merely an underlying trend that spans both districts.\n",
    "\n",
    "![](../NYC/NYC_plots/sales_histogram_19-27.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter optimization\n",
    "\n",
    "We initially fit the hyperparameters $\\sigma_\\beta$, $\\sigmaf$, $\\ell$ and $\\sigman$ by optimizing the marginal log-likelihood of the data within a single district. We choose district 27 as it contains more sales. We hold $\\sigma_\\mu$ fixed to 10 to give the district means $\\mu_j$ a fairly uninformative prior. The fitted hyperparameters were $\\sigman=0.4179$, $\\sigmaf=0.2426$, $\\sigma_\\beta=0.1306$, and $\\ell=3378.5800~\\text{ft}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cliff face\n",
    "\n",
    "We seek the treatment effect function $\\tau(\\border)$ between the two districts. We could proceed by computing the joint predictive distributions $g_\\treat{}(\\sentinels),g_\\ctrol{}(\\sentinels) \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigma_\\beta,\\sigmaf,\\ell,\\sigman$, which is a $2 \\numsent$-dimensional multivariate normal distribution. Instead, we obtain the posterior means of the $\\beta_{1j}$ and $\\beta_{2j}$ coefficients, extract the residuals $Y_\\treat{}-D_\\treat{} \\hat{\\beta}$ and $Y_\\ctrol{}-D_\\ctrol{} \\hat{\\beta}$. This decorrelates $g_\\treat{}(\\sentinels)$ and $g_\\ctrol{}(\\sentinels)$ so they become independent multivariate normal distributions $g_\\treat{}(\\sentinels) \\mid Y_\\treat{}, \\hat\\beta, \\sigmaf,\\ell,\\sigman$ and $g_\\ctrol{}(\\sentinels) \\mid Y_\\ctrol{}, \\hat\\beta, \\sigmaf,\\ell,\\sigman$. In this example, we find that the posterior variance of $\\beta$ is low, and therefore the two approaches yield very similar results, but conditioning on the estimate of $\\beta$ is computationally convenient. We therefore proceed with this two-step approach.\n",
    "\n",
    "Equipped with multivariate normal posteriors on $g_\\ctrol{}(\\sentinels)$ and $g_\\treat{}(\\sentinels)$, which are uncorrelated conditional on $\\beta=\\hat\\beta$, we can now take their difference according to the procedure outline in section \\ref{sec:twogp}, to obtain the posterior distribution of the cliff-face $\\tau(\\sentinels)$ obtained at the sentinel locations. \n",
    "The cliff-face is shown in Figure \\ref{fig:NYC_cliff_face}, and shows that the estimated $\\tau(\\sentinels)$ is negative everywhere along the border, which corresponds to higher property prices in district 27. \n",
    "However, the credible envelope is wide, especially in the Southern section of the border, and therefore it isn't clear that this effect isn't due to random variation.\n",
    "\n",
    "The treatment effect can also be visualized directly in Figure \\ref{fig:NYC_3d} as the difference between the two log-price mean surfaces $g(\\svec)$. This pictures also gives a better sense of the important spatial variation in prices captured by the model, which explains the wide credible envelope in the cliff face, despite the large number of sales in both districts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\\label{fig:NYC_cliff_face}NYC cliff face](../NYC/NYC_plots/NYC_cliff_face.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\\label{fig:NYC_3d}NYC surface plot](../NYC/NYC_plots/NYC_surface_plot_multi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Log-Price Increase\n",
    "\n",
    "The cliff-face plot shows a negative treatment effect everywhere along the border, which can be averaged by the estimators we developed in section \\ref{sec:ate}. The most obvious approach is to take an unweighted mean at each equispaced sentinel, which has posterior distribution\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    \\unifavg \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\hat{\\beta}, \\ell &\\sim \\normal\\del{-0.20, 0.09^2}\\,\\text{and tail probability} \\\\\n",
    "    \\Pr\\del{\\unifavg > 0 \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\hat{\\beta}, \\ell} &= 1.48\\% \\,.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "The inverse-variance weighted mean estimator is robust to changes in the border topology, and gives higher weight to sections of the border where the difference in house prices is easier to measure. It is guaranteed to minimize the posterior variance amongst weighted mean estimators, which is reflected here by the narrower posterior distribution\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    \\invvar \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\hat{\\beta}, \\ell &\\sim \\normal\\del{-0.20, 0.05^2}\\,\\text{and reduced tail probability} \\\\\n",
    "    \\Pr\\del{\\invvar > 0 \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\hat{\\beta}, \\ell} &= 0.01\\% \\,.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "The posterior mean estimate corresponds to a 21% increase in price per square foot from district 19 to district 27.\n",
    "\n",
    "All estimators \\[except $\\taurho$ for now\\] are shown in Table \\ref{table:NYC_ate}. For each estimand, we show the mean and standard deviation of its posterior distribution, and the tail probability $\\Pr\\del{\\tau > 0 \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\hat{\\beta}, \\ell}$ of the average treatment being greater than zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Estimand  | Posterior Mean | Posterior Standard Deviation | Posterior Tail Prob |\n",
    "|:----------:|:--------------:|:----------------------------:|:-------------------:|\n",
    "| $\\unifavg$ |      -0.20     |             0.09             |        1.48%        |\n",
    "|  $\\invvar$ |      -0.20     |             0.05             |        0.01%        |\n",
    "| $\\tauproj$ |      -0.21     |             0.08             |        0.46%        |\n",
    "|  $\\taugeo$ |      -0.19     |             0.10             |        2.54%        |\n",
    "|  $\\taupop$ |      -0.19     |             0.06             |        0.04%        |\n",
    "Table: Average treatment effect estimators for New York school district house prices example. \\label{table:NYC_ate}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant Difference in Price?\n",
    "\n",
    "The inverse-variance weighted mean treatment effect hints at a significant treatment effect. \n",
    "But the posterior tail probability cannot be interpreted as a $p$-value.\n",
    "For this, we turn to the three tests developed in section \\ref{sec:hypothesis_testing}.\n",
    "In applied settings, running multiple tests invalidates their results, \n",
    "but as we are proposing this new methodology,\n",
    "we apply all three tests in order to gain insight into their differences.\n",
    "Their results are found in Table \\ref{table:NYC_tests}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Test                   | $p$-value |\n",
    "|------------------------|-----------|\n",
    "| $\\chi^2$ bootstrap     | 0.003     |\n",
    "| mLL bootstrap          | 0.001     |\n",
    "| $\\invvar$ uncalibrated | 0.0003    |\n",
    "| $\\invvar$ calibrated   | 0.0004    |\n",
    "Table: Results of hypothesis tests for New York school district house prices example. \\label{table:NYC_tests}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[no longer true]**\n",
    "The three tests tell very different stories. \n",
    "The $\\chi^2$ test fails to reject the null hypothesis even at the $\\alpha=0.1$ level.\n",
    "This strongly contradicts the inverse-variance test and its low $p$-value of $0.0005$,\n",
    "backed by the likelihood-ratio test with $p=0.0015$.\n",
    "The possibility of such a contradiction was anticipated in section XX, where we saw that the $\\chi^2$ has the lowest power of the three tests, and therefore could easily fail to reject an effect that is easily detected by the inverse-variance test.\n",
    "Because the inverse-variance test has the highest power in detecting constant treatment effects, we would recommend its use in applications — such as this one — where a very heterogenous treatment effect is not expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### placebo tests\n",
    "\n",
    "To assess the validity of the three tests, we apply the placebo tests that we devised in Section X. \n",
    "Within each district, we split the data in half by a line at angles $1\\degree,3\\degree,5\\degree,6\\degree,\\ldots,179\\degree$. \n",
    "Because these lines were drawn arbitrarily, we don't expect a discontinuous treatment effect between the two halves, and so we hope to see a uniform distribution of placebo $p$-values.\n",
    "However, these tests will be highly correlated, \n",
    "and so the low effective sample size could lead to some apparent departures from uniformity.\n",
    "There is in fact visible autocorrelation in the graphs of placebo $p$-values as a function of angle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\\label{fig:nyc_placebos} Placebo tests for significance tests applied to NYC school district house price example, applied within districts 19 and 27. The three rows respectively show results for the marginal log-likelihood bootstrap test, chi-squared bootrap test, and calibrated inverse-variance test. The first column shows the placebo p-value as a function of the border angle, in order to visualize the high auto-correlation of the placebo tests. The second column shows histograms of the placebo p-values, with the black vertical line indicating the uniform distribution for comparison.](../NYC/NYC_plots/NYC_placebos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mLL placebo $p$-values show a pronounced bias towards low values.\n",
    "This seems to confirm our concern that the marginal log-likelihood may be sensitive to features of the data other than the discontinuity at the border.\n",
    "In particular, model misspecification, which is a big concern in spatial models, makes the interpretation of the mLL test unreliable.\n",
    "Based on this vulnerability, and its manifestation in this example, we do not recommend relying on the likelihood-ratio test.\n",
    "\n",
    "The $\\chi^2$ test shows more robustness, with Figure \\ref{fig:nyc_placebos}(d) showing some negative bias in district 27, and some positive bias in district 19, which could simply be due to the low effective sample size.\n",
    "We therefore believe that the $\\chi^2$ test will continue to be reliable under misspecification.\n",
    "It is only due to its low power that we hesitate to recommend its use in applications where the treatment effect is expected to be fairly homogenous.\n",
    "\n",
    "Lastly, the inverse-variance placebo $p$-values display no obvious bias, with Figure \\ref{fig:nyc_placebos}(f) close to uniformly distributed, and Figure  \\ref{fig:nyc_placebos}(e) showing a lower auto-correlation than the mLL and $\\chi^2$ tests.\n",
    "The high power and robustness of the inverse-variance test make a strong argument for its use in most applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pairwise treatment effect (all districts)\n",
    "\n",
    "![\\label{fig:NYC_pairwise} Pairwise effect size between adjacent districts. The thickness of each border is proprtional to the posterior effect size defined as $\\E(\\invvar \\mid Y) \\big/ (\\var(\\invvar \\mid Y))^{1/2}$, indicating the strength of the evidence towards a discontinuity in house prices at that border. Effect sizes greater than 2 are shown in orange.](../NYC/NYC_plots/pairwise_multi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geographic regression discontinuity designs (GeoRDDs) arise in situations where a treatment or change affects outcomes in one region, but not in an adjacent control region.\n",
    "For outcomes that vary spatially, a direct comparison of mean outcomes between $Y_\\treat$ and $Y_\\ctrol$, such as a $t$-test, is an invalid estimator of the treatment effect, as it is confounded by the spatial covariates.\n",
    "However, if potential outcomes under treatment and control vary smoothly in space, then units adjacent to the border are comparable, and form a natural experiment.\n",
    "This idea is analogous to univariate regression discontinuity designs (1D RDDs), where a single “forcing” variable controls the treatment assignment instead of a border separating two geographical regions.\n",
    "We use this analogy to motivate a general framework for the analysis of GeoRDDs.\n",
    "Univariate methods can be abstracted to three steps: (1) fit a smooth function on either side of the threshold; (2) extrapolate the functions to the threshold; and (3) take the difference of the two extrapolations to estimate the treatment effect at the threshold.\n",
    "For GeoRDDs we propose to (1) fit a smooth surface on either side of the border; (2) extrapolate the surfaces to the border; and (3) take the difference of the two extrapolations to estimate the treatment effect along the border.\n",
    "\n",
    "The same analogy has motivated previous researchers to extend methods developed for 1D RDDs to GeoRDDs.\n",
    "In applied settings, researchers have used the signed distance from the border as the forcing variable in a 1D RDD, but the resulting estimator is still spatially confounded.\n",
    "In this paper, our aim was to recognize the importance of the geographical aspect of the problem, and therefore draw from the spatial statistics literature, which brings a rich set of tools designed specifically to model and exploit spatial correlations to obtain more powerful inference.\n",
    "We therefore used Gaussian process regression, known as kriging in the spatial statistics literature, to fit the smooth surfaces to the outcomes in step (1) of our general framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our approach yields a multivariate normal posterior distribution of the functional treatment effect for a collection of “sentinel” points along the border: the “cliff face” estimate.\n",
    "But this primary output is somewhat unsatisfactory, as it doesn't answer two immediate questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, can we estimate the average treatment effect (ATE)? \n",
    "Defining an “average treatment effect” estimand turns out to have surprising pitfalls.\n",
    "A particularly intriguing aspect of GeoRDDs is that the treatment effect is a real function defined everywhere on the border, which is a one-dimensional manifold embedded in a two-dimensional space.\n",
    "The geometry makes the very reasonable idea of integrating the treatment effect linearly along the border quite unsuitable.\n",
    "We showed that this ATE estimand is undesirably sensitive to the topology of the border: straight segments are given less weight than wiggly segments of the border, which is unlikely to be the analyst's intention.\n",
    "A more suitable approach is to weight sentinels by the inverse of the posterior covariance, which yields an ATE estimate that is robust to the topology of the border, and is also the minimum variance ATE estimate, thus fully utilizing the information available in the GeoRDD.\n",
    "But it lacks an easily interpretable estimand, motivated as it is by the properties of its posterior: we estimate what we can rather than what we want.\n",
    "Another approach is to project observed units onto the border, instead of evenly spaced sentinels, an take the unweighted mean of the treatment effect estimated at those locations.\n",
    "This estimate is also robust to border topology, and the estimand allows for a finite population interpretation that may feel more natural to practicioners.\n",
    "\n",
    "Secondly, when can we say that we have detected a statistically significant treatment effect?\n",
    "We proposed three tests, one based on the inverse-variance weighted ATE, on a marginal likelihood comparison, and a “chi-squared” test.\n",
    "A tail probability can be derived heuristically from the inverse-variance weighted ATE's posterior distribution, but a calibration step, either through a parametric bootstrap or analytically, is necessary to turn this Bayesian pseudo-$p$-value into a valid frequentist $p$-value.\n",
    "Note that the same procedure to obtain a valid test could be followed using any of the average treatment effect estimates defined in section \\ref{sec:ate}.\n",
    "The second test compares the marginal likelihood under the GeoRDD \\eqref{eq:spec2gp} versus a single Gaussian process with the same covariance parameters spanning both regions, the null model.\n",
    "We argue that the marginal likelihood test is sensitive to model misspecification and doesn't explicitly target the detection of a treatment effect at the border, and therefore do not recommend its use.\n",
    "The “chi-squared test” addresses this issue, as it uses a statistic that is calculated directly  from the border treatment effect's posterior mean vector and covariance matrix.\n",
    "The test statistic is inspired by a classical chi-squared test for testing whether the mean of a multivariate normal distribution is zero, but in this setting it does not have a $\\chi^2$ distribution in this setting.\n",
    "We therefore again use a parametric bootstrap to obtain its null distribution.\n",
    "The “chi-squared” test targets the sharp null hypothesis of no treatment effect anywhere along the border, while the inverse-variance test targets the weak null hypothesis of zero ATE.\n",
    "While the sharp null is more general, we find that the “chi-squared” test has lower power than the inverse-variance test.\n",
    "Therefore, we recommend the use of the inverse-variance test in contexts where the treatment effect, if non-zero, is expected to be mostly positive everywhere, or negative everywhere along the border, or when the average treatment effect is of primary scientific interest.\n",
    "\n",
    "Besides ATE and hypothesis testing, another potential question of interest is whether heterogeneous treatment effects are detectable along the border.\n",
    "In other words, can we reject the null hypothesis that the first derivative of the treatment effect is zero everywhere along the border?\n",
    "We have not yet explored this avenue of research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply our method to a publically available dataset of New York City property sales.\n",
    "The city is divided into 32 school districts, and attendance to each public school is partially dictated by having a home address in its district.\n",
    "It is commonly believed that some districts have better schools than others, and that parents seeking to place their children in the best schools drive up real estate prices in the districts with better reputations.\n",
    "As a consequence, one would predict that residential property prices per square foot change discontinuously at the district borders, an effect that we seek to detect and estimate.\n",
    "Focusing on the border between districts 19 and 27, we do indeed detect a jump in prices.\n",
    "In this example, the different ATE estimators actually yield very similar estimates, roughly corresponding to a 20% increase in price per square foot from district 19 to 27.\n",
    "While the posterior means agree, the inverse-variance weighted mean does indeed yield the estimate with the highest posterior precision.\n",
    "The three hypothesis tests also substantially agree that there is a significant treatment effect at the border, but they report different $p$-values.\n",
    "The three tests may very well lead to different conclusions in other applied settings.\n",
    "The placebo tests suggest that in this example the test based on the inverse-variance weighted mean is more robust and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main limitation of our approach to GeoRDDs is the reliance on modeling assumptions.\n",
    "We modeled the response surfaces as two independent Gaussian processes, with iid normal noise for each observation.\n",
    "Furthermore, we assumed an isotropic covariance function, with parameters equal in the treatment and control regions, and in particular we chose the squared exponential covariance.\n",
    "None of these assumptions are justified a priori, so their reasonableness should be evaluated with each application.\n",
    "The squared exponential covariance function makes smoothness assumptions that are often considered unrealistic in spatial settings, and so the Matérn covariance family is often recommended as a more robust alternative.\n",
    "\n",
    "We use Gaussian processes as non-parametric smoothing devices used to capture spatial correlations, but do not think of them as truthful approximations to the data generating mechanism.\n",
    "Some care must therefore be taken not to lean heavily on this modeling assumption.\n",
    "In particular, we recommend that hypothesis tests always be accompanied by placebo tests. \n",
    "By applying the same procedure on data where no treatment was applied, we can verify that the test behaves correctly under the null hypothesis.\n",
    "\n",
    "Because of the need to extrapolate the fitted processes to the border, GeoRDDs are particularly vulnerable to the limitations of Gaussian processes when extrapolating.\n",
    "The distinction between interpolation and extrapolation of spatial models is explored in some depth in <cite data-cite=\"stein2012interpolation\">(Stein, 2012)</cite>.\n",
    "We expect that methodological advances that improve the extrapolating behavior of Gaussian processes would also improve the robustness of our method.\n",
    "For example, <cite data-cite=\"wilson2013gaussian\">(Wilson and Ryan Adams, 2013)</cite> develop spectral mixture (SM) covariance kernels with good extrapolating behavior, which could be applied beneficially to GeoRDDs.\n",
    "However, SM kernels are aimed at time-series signals with some periodic or oscillatory behavior, which is more unusual in spatial applications, and may therefore not be as well-suited for use with GeoRDDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of Gaussian process regression to analyse GeoRDDs gives flexibility and extensibility to the method.\n",
    "This presents many opportunities for future research, inspired by the past and future development of methods in spatial statistics and machine learning that are based on Gaussian processes.\n",
    "In spatial statistics, kriging has been used as the foundation for a plethora of spatial models, which may be adapted for the purposes of analyzing GeoRDDs.\n",
    "<cite data-cite=\"banerjee2014hierarchical\">(Banerjee, 2014)</cite> provides a good introduction to the richness of the spatial statistics field.\n",
    "For example, if the outcomes are binary, proportions, or counts, then binomial or Poisson likelihoods could be substituted for the iid normal likelihood used in this paper. \n",
    "Note that the estimand is no longer defined as a discontinuity in the expectation function of the potential outcomes, as in \\eqref{eq:functional_estimand}, but as the difference between two latent processes that are hypothesized by the model.\n",
    "\n",
    "The framework and techniques of this paper could also be extended to spatio-temporal settings.\n",
    "If the treatment is only applied to the treatment region after a time $t*$, one could envision a three-dimensional RDD consisting of the geographical border in the spatial dimensions, and a straight line through $t*$ in the temporal dimension.\n",
    "The only necessary modification to our approach is that the Gaussian process model would need to be augmented with a temporal component, for example with an anisotropic squared exponential covariance function.\n",
    "Longitudinal studies could also be handled by such an approach, with the addition of random intercepts for each unit.\n",
    "We leave spatio-temporal RDDs using Gaussian process models to future research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariances in 2GP model\n",
    "\n",
    "**[needs a bit of love]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    m_\\treat, m_\\ctrol   &\\sim \\normal\\del{0,\\sigmamu^2} \\\\\n",
    "    \\beta &\\sim \\normal\\del{0,\\sigmabeta^2} \\\\\n",
    "    \\cov(Y_{i\\treat},m_\\treat)  &= \\sigmamu^2 \\\\\n",
    "    \\cov(Y_{i\\ctrol},m_\\ctrol)  &= \\sigmamu^2 \\\\\n",
    "    \\cov(Y_{i\\treat},\\beta)&= \\sigmabeta^2 \\svec_i \\trans \\svec_i \\\\\n",
    "    \\cov(Y_{i\\ctrol},\\beta)&= \\sigmabeta^2 \\svec_i \\trans \\svec_i \\\\\n",
    "    \\cov\\del{Y_{i\\treat}, f_{\\treat}(\\svec')} &= k(\\svec_i,\\svec') \\\\\n",
    "    \\cov\\del{Y_{i\\ctrol}, f_{\\ctrol}(\\svec')} &= k(\\svec_i,\\svec') \\\\\n",
    "    \\cov\\del{Y_{i\\treat}, f_{\\ctrol}(\\svec')} &= 0 \\\\\n",
    "    \\cov\\del{Y_{i\\ctrol}, f_{\\treat}(\\svec')} &= 0 \\\\\n",
    "    \\cov(Y_{i\\treat},Y_{j\\treat}) &= \\sigmamu^2 + \\sigmabeta^2 \\svec_i\\trans \\svec_j + k(\\svec_i,\\svec_j) + \\delta_{ij}\\sigman^2 \\\\\n",
    "    \\cov(Y_{i\\treat},Y_{j\\ctrol}) &= \\sigmabeta^2 \\svec_i\\trans \\svec_j\n",
    "\\end{split}\n",
    "\\eqlabel{eq:covariances}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior mean of $\\hat\\beta$\n",
    "\n",
    "**[Derivation of $\\hat{\\beta}$ below: should it be in the covariates section? should it be in an appendix? is it too elementary to be in this paper?]**\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    \\Sigma_{Y \\mid \\beta} &\\equiv \\cov\\del{Y \\mid \\beta } \n",
    "        & \\text{conditional variance of $Y$} \\\\\n",
    "    \\cov\\del{Y_i , Y_j \\mid \\beta } &= \\sigman^2 \\delta_{ij} + k\\del{\\svec_i,\\svec_j} \\delta_{\\district\\sbr{i},\\district\\sbr{j}} & \\text{(block diagonal)}\\\\\n",
    "    \\Sigma_\\beta &\\equiv \\cov\\del{\\beta} = \\sigma_\\beta^2 I_p\n",
    "        & \\text{prior variance of $\\beta$} \\\\\n",
    "    \\Sigma_Y &\\equiv \\cov\\del{Y} = \\Sigma_{Y \\mid \\beta} + D\\trans \\Sigma_\\beta D\n",
    "        & \\text{unconditional variance of $Y$} \\\\\n",
    "    T_\\beta &= D\\trans \\Sigma_{Y \\mid \\beta}^{-1} D + \\Sigma^{-1}_\\beta \n",
    "        & \\text{precision matrix of $\\beta$} \\\\\n",
    "    \\hat\\beta &= \\del{T_\\beta^{-1} D} \\del{ \\Sigma_{Y \\mid \\beta}^{-1} \\del{Y-\\mu}}\n",
    "        & \\text{posterior mean of $\\beta$}\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration of inverse-variance test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\label{sec:calibration}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's remind ourselves how the inverse-variance posterior mean estimate was obtained. We will then derive its distribution under the null hypothesis.\n",
    "\\begin{equation}\\begin{split}\n",
    "    \\invvar \\mid Y_\\treat{}, Y_\\ctrol{}, \\sigmaf, \\sigman, \\ell &\\sim \\normal\\del{\\mu_{\\invvar \\mid Y}, \\Sigma_{\\invvar \\mid Y}} \\\\\n",
    "    \\mu_{\\invvar \\mid Y} &\\approx \\del{\\ones\\trans \\Sigma_{\\sentinels \\mid Y}^{-1} \\mu_{\\sentinels \\mid Y}} \\big/ \\del{\\ones\\trans \\Sigma_{\\sentinels \\mid Y}^{-1} \\ones}  \\\\\n",
    "    \\mu_{\\sentinels \\mid T} &\\equiv \\cov\\del{g_\\treat{}(\\sentinels), Y_\\treat{}} \\cov\\del{Y_\\treat{}}^{-1}  Y_\\treat{} \\\\\n",
    "    \\mu_{\\sentinels \\mid C} &\\equiv \\cov\\del{g_\\treat{}(\\sentinels), Y_\\ctrol{}} \\cov\\del{Y_\\ctrol{}}^{-1}  Y_\\ctrol{} \\\\\n",
    "    \\mu_{\\border \\mid Y} &=  \\mu_{\\sentinels \\mid T} - \\mu_{\\sentinels \\mid C} \\\\\n",
    "    \\mu_{\\invvar \\mid Y} &= \\del{\\ones\\trans \\Sigma_{\\sentinels \\mid Y}^{-1} \\mu_{\\sentinels \\mid Y}} \\big/ \\del{\\ones\\trans \\Sigma_{\\sentinels \\mid Y}^{-1} \\ones}  \\\\\n",
    "\\end{split}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under our parametric null hypothesis $H_0$, $Y_\\treat{}$ and $Y_\\ctrol{}$ are drawn from a single smooth Gaussian process, with no discontinuity at the border. \n",
    "Their joint covariance is\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    \\cov \\del{\\begin{pmatrix}Y_\\treat{} \\\\ Y_\\ctrol{}\\end{pmatrix} \\mid H_0 } &= \\begin{bmatrix}\n",
    "                        \\Sigma_{TT} & \\Sigma_{TC} \\\\\n",
    "                        \\Sigma\\trans_{TC} & \\Sigma_{CC}\n",
    "                    \\end{bmatrix}\\,\\text{where} \\\\\n",
    "    \\Sigma_{TT} &\\equiv K_{TT} + \\sigman^2 I_{n_\\treat{}} \\\\\n",
    "    \\Sigma_{CC} &\\equiv K_{CC} + \\sigman^2 I_{n_\\ctrol{}} \\\\\n",
    "    \\Sigma_{TC} &\\equiv K_{TC}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "where the entries of $K_{TT}$, $K_{CC}$ and $K_{TC}$ are obtained simply be evaluating the Gaussian process kernel for each pair of points within and between the treatment and control regions.\n",
    "The predicted mean outcomes at the sentinels $\\mu_{\\sentinels \\mid T}$ and $\\mu_{\\sentinels \\mid T}$ are obtained by left-multiplying $Y_\\treat{}$ and $Y_\\ctrol{}$ by matrices that are deterministic functions of the unit locations and the hyperparameters \n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    A_\\treat{} &\\equiv \\cov\\del{g_\\treat{}(\\sentinels), Y_\\treat{}} \\cov\\del{Y_\\treat{}}^{-1} = K_{\\sentinels T} \\Sigma_{TT}^{-1} \\,\\text{, and} \\\\\n",
    "    A_\\ctrol{} &\\equiv \\cov\\del{g_\\ctrol{}(\\sentinels), Y_\\ctrol{}} \\cov\\del{Y_\\ctrol{}}^{-1} = K_{\\sentinels C} \\Sigma_{CC}^{-1}\\,.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "where we dropped the explicit conditioning on the null hypothesis for readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint distribution of $\\mu_{\\sentinels \\mid T}$ and $\\mu_{\\sentinels \\mid T}$ is consequently also multivariate normal with mean zero and covariance\n",
    "\\begin{equation}\n",
    "    \\cov \\del{\\begin{pmatrix}A_\\treat{} Y_\\treat{} \\\\ A_\\ctrol{} Y_\\ctrol{} \\end{pmatrix} \\mid H_0 } = \\begin{bmatrix}\n",
    "                        A_\\treat{} \\Sigma_{TT} A_\\treat{}\\trans & A_\\treat{} \\Sigma_{TC} A_\\ctrol{}\\trans \\\\\n",
    "                        \\del{A_\\treat{} \\Sigma_{TC} A_\\ctrol{} \\trans}\\trans & A_\\ctrol{} \\Sigma_{CC} A_\\ctrol{}\\trans\n",
    "                    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "Continuing in this fashion, $\\mu_{\\border \\mid Y}$ is yet another zero-mean multivariate normal with covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    \\cov \\del{\\mu_{\\border \\mid Y} \\mid H_0} &= \\cov{ A_\\treat{} Y_\\treat{} - A_\\ctrol{} Y_\\ctrol{} } \\\\\n",
    "        &= A_\\treat{} \\Sigma_{TT} A_\\treat{}\\trans + A_\\ctrol{} \\Sigma_{CC} A_\\ctrol{}\\trans - A_\\treat{} \\Sigma_{TC} A_\\ctrol{}\\trans -  \\del{A_\\treat{}\\Sigma_{TC} A_\\ctrol{}\\trans}\\trans\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted mean estimators are linear transformation of $\\mu_{\\border \\mid Y}$, and so under $H_0$, they are normally distributed with mean zero.\n",
    "For a weight vector $\\vvec$, its variance is given by\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    \\var\\del{\\bar{\\tau}^\\vvec \\mid H_0} &= \\cov\\del{ \\frac{\\vvec \\trans \\mu_{\\border \\mid Y}}{\\ones_{\\numsent}\\trans \\vvec}} \\\\\n",
    "    &= \\frac{\\vvec \\trans \\cov \\del{\\mu_{\\border \\mid Y}} \\vvec}{\\del{\\ones_{\\numsent}\\trans \\vvec}^2}\n",
    "    \\,.\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this null distribution the $p$-value follows:\n",
    "\\begin{equation}\n",
    "    \\Pr\\del{ \\abs{\\bar{\\tau}^\\vvec} > \\abs{\\bar{\\tau}_{obs}^\\vvec} \\mid H_0} = 2 \\Phi\\del{ -\\frac{\\abs{\\bar{\\tau}_{obs}^\\vvec}}{\\sqrt{\\var\\del{\\bar{\\tau}^\\vvec \\mid H_0}}} }\\,.\n",
    "\\end{equation}\n",
    "Our calibrated inverse-variance test is the special case of this final step where the weights are chosen to be $\\vvec = \\Sigma^{-1}_{\\border \\mid Y} \\ones_{\\numsent}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiggly border simulation results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\newgeometry{margin=5cm} % modify this if you need even more space\n",
    "\\begin{landscape}\n",
    "\n",
    "\\begin{table}\n",
    "\\begin{tabular}{r|ccccccccccccc}\n",
    "\t& $n_{\\mathrm{wiggles}}$ & $\\widehat{\\unifavg}$ & $\\unifavg$ & $\\widehat{\\invvar}$ & $\\invvar$ & $\\widehat{\\taurho}$ & $\\taurho$ & $\\widehat{\\tauproj}$ & $\\tauproj$ & $\\widehat{\\taugeo}$ & $\\taugeo$ & $\\widehat{\\taupop}$ & $\\taupop$\\\\\n",
    "\t\t\\hline\n",
    "\t\t1 & 0 & 0.85 (0.08) & 1.00 & 1.16 (0.05) & 1.20 & 1.30 (0.05) & 1.34 & 1.28 (0.05) & 1.33 & 0.85 (0.08) & 1.00 & 1.30 (0.05) & 1.34 \\\\\n",
    "\t\t2 & 1 & 0.84 (0.08) & 0.99 & 1.06 (0.04) & 1.13 & 1.28 (0.05) & 1.32 & 1.28 (0.05) & 1.32 & 0.84 (0.08) & 0.98 & 1.27 (0.05) & 1.31 \\\\\n",
    "\t\t3 & 1 & 0.84 (0.08) & 0.99 & 1.06 (0.04) & 1.13 & 1.28 (0.05) & 1.32 & 1.28 (0.05) & 1.32 & 0.84 (0.08) & 0.98 & 1.27 (0.05) & 1.31 \\\\\n",
    "\t\t4 & 2 & 0.81 (0.07) & 0.95 & 1.05 (0.04) & 1.12 & 1.23 (0.05) & 1.27 & 1.29 (0.05) & 1.33 & 0.82 (0.07) & 0.96 & 1.24 (0.05) & 1.28 \\\\\n",
    "\t\t5 & 3 & 0.78 (0.07) & 0.91 & 1.05 (0.04) & 1.12 & 1.17 (0.05) & 1.20 & 1.29 (0.05) & 1.33 & 0.81 (0.07) & 0.95 & 1.23 (0.05) & 1.26 \\\\\n",
    "\t\t6 & 6 & 0.69 (0.07) & 0.79 & 1.05 (0.04) & 1.12 & 1.01 (0.05) & 1.03 & 1.29 (0.05) & 1.33 & 0.81 (0.07) & 0.94 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t7 & 10 & 0.61 (0.06) & 0.67 & 1.05 (0.04) & 1.12 & 0.86 (0.05) & 0.86 & 1.29 (0.05) & 1.33 & 0.81 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t8 & 15 & 0.54 (0.07) & 0.58 & 1.05 (0.04) & 1.12 & 0.74 (0.06) & 0.73 & 1.29 (0.05) & 1.33 & 0.81 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t9 & 25 & 0.47 (0.07) & 0.48 & 1.05 (0.04) & 1.12 & 0.60 (0.06) & 0.58 & 1.29 (0.05) & 1.33 & 0.81 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t10 & 39 & 0.42 (0.07) & 0.41 & 1.05 (0.04) & 1.12 & 0.51 (0.07) & 0.49 & 1.29 (0.05) & 1.33 & 0.81 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t11 & 63 & 0.38 (0.07) & 0.36 & 1.05 (0.04) & 1.12 & 0.44 (0.07) & 0.41 & 1.29 (0.05) & 1.33 & 0.80 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t12 & 100 & 0.35 (0.08) & 0.32 & 1.05 (0.04) & 1.12 & 0.39 (0.08) & 0.35 & 1.29 (0.05) & 1.33 & 0.80 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t13 & 158 & 0.33 (0.08) & 0.30 & 1.05 (0.04) & 1.12 & 0.36 (0.08) & 0.32 & 1.29 (0.05) & 1.33 & 0.80 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t14 & 251 & 0.32 (0.08) & 0.28 & 1.05 (0.04) & 1.12 & 0.34 (0.08) & 0.29 & 1.29 (0.05) & 1.33 & 0.80 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t15 & 398 & 0.31 (0.08) & 0.27 & 1.05 (0.04) & 1.12 & 0.32 (0.08) & 0.28 & 1.29 (0.05) & 1.33 & 0.80 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t16 & 630 & 0.31 (0.08) & 0.26 & 1.05 (0.04) & 1.12 & 0.31 (0.08) & 0.27 & 1.29 (0.05) & 1.33 & 0.80 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\t17 & 1000 & 0.30 (0.08) & 0.26 & 1.05 (0.04) & 1.12 & 0.31 (0.08) & 0.26 & 1.29 (0.05) & 1.33 & 0.80 (0.07) & 0.93 & 1.22 (0.05) & 1.25 \\\\\n",
    "\t\\end{tabular}\n",
    "\t\\caption{Table of posterior mean, posterior standard deviation and true value for each average treatment effect estimand as the wiggliness of the border is increased.}\n",
    "\\end{table}\n",
    "\\end{landscape}\n",
    "\\restoregeometry"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "983px",
    "left": "0px",
    "right": "977px",
    "top": "67px",
    "width": "300px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc_position": {
   "height": "974px",
   "left": "0px",
   "right": "746px",
   "top": "106px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
